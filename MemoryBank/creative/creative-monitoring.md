# –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

üé®üé®üé® **ENTERING CREATIVE PHASE: MONITORING & LOGGING SYSTEM** üé®üé®üé®

## –û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞

–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ observability –¥–ª—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –±–∏–ª—å—è—Ä–¥–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—é—â–∞—è centralized logging, metrics collection, performance monitoring, error tracking, security monitoring –∏ alerting. –°–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –æ–±–µ—Å–ø–µ—á–∏—Ç—å comprehensive visibility –≤–æ –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –æ—Ç infrastructure metrics –¥–æ business KPIs, —Å real-time alerting –∏ historical analysis capabilities.

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

### –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- **Centralized Logging**: –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ª–æ–≥–æ–≤ —Å–æ –≤—Å–µ—Ö –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤ –≤ –µ–¥–∏–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
- **Metrics Collection**: –°–±–æ—Ä application, infrastructure –∏ business metrics
- **Real-time Monitoring**: Live dashboards –¥–ª—è operational awareness
- **Alerting System**: Automated notifications –¥–ª—è critical events
- **Error Tracking**: Comprehensive error monitoring —Å stack traces
- **Performance Monitoring**: Response times, throughput, resource utilization
- **Security Monitoring**: Authentication failures, suspicious activities, data breaches
- **Log Analysis**: Search, filtering, correlation –∏ pattern detection

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
- **High Availability**: 99.9% uptime –¥–ª—è monitoring infrastructure
- **Low Latency**: < 30 seconds –¥–ª—è metric delivery
- **Storage Efficiency**: Log retention policies –¥–ª—è cost optimization
- **Query Performance**: < 5 seconds –¥–ª—è dashboard loading
- **Scalability**: Support –¥–ª—è 10K+ concurrent users
- **Data Privacy**: Sensitive data masking –∏ GDPR compliance
- **Resource Usage**: < 5% overhead –Ω–∞ monitored services
- **Integration**: Seamless integration —Å existing microservices

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
- **Multi-service Architecture**: 5+ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ tech stacks
- **Container Environment**: Docker-based deployment
- **Cloud Deployment**: Support –¥–ª—è cloud –∏ on-premise
- **Network Reliability**: Resilient –∫ network partitions
- **Storage Capacity**: Efficient data compression –∏ archival
- **Security**: Encrypted data transmission –∏ storage
- **Compliance**: GDPR, data retention policies
- **Cost Efficiency**: Optimized resource utilization

### Operational —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- **24/7 Monitoring**: Continuous operation requirements
- **Multi-tenant Support**: Isolation –º–µ–∂–¥—É development/staging/production
- **Backup & Recovery**: Data protection –∏ disaster recovery
- **Access Control**: Role-based access to monitoring data
- **API Integration**: Programmatic access –¥–ª—è automation
- **Documentation**: Comprehensive runbooks –∏ troubleshooting guides

## –í–∞—Ä–∏–∞–Ω—Ç—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

### –í–∞—Ä–∏–∞–Ω—Ç 1: ELK Stack + Prometheus/Grafana

**–û–ø–∏—Å–∞–Ω–∏–µ**: –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è Elasticsearch, Logstash, Kibana –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è + Prometheus/Grafana –¥–ª—è –º–µ—Ç—Ä–∏–∫.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤**:
```
Applications/Services
       ‚Üì
   Filebeat/Fluentd (Log Shipping)
       ‚Üì
   Logstash (Processing)
       ‚Üì
   Elasticsearch (Storage)
       ‚Üì
   Kibana (Visualization)

Applications/Services
       ‚Üì
   Prometheus (Metrics Collection)
       ‚Üì
   Grafana (Dashboards)
       ‚Üì
   AlertManager (Alerting)
```

**Technology Stack**:
- **Logging**: Elasticsearch + Logstash + Kibana + Filebeat
- **Metrics**: Prometheus + Grafana + AlertManager
- **Tracing**: Jaeger –∏–ª–∏ Zipkin
- **Error Tracking**: Sentry integration
- **Infrastructure**: Docker Compose –∏–ª–∏ Kubernetes

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- Mature ecosystem —Å extensive community support
- Powerful search capabilities –≤ Elasticsearch
- Rich visualization options –≤ Kibana –∏ Grafana
- Excellent alerting capabilities
- Strong integration ecosystem
- Proven scalability –¥–ª—è enterprise workloads

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**:
- High resource consumption (–æ—Å–æ–±–µ–Ω–Ω–æ Elasticsearch)
- Complex setup –∏ configuration
- Multiple tools to maintain
- Steep learning curve
- Expensive at scale
- Potential vendor lock-in —Å Elastic Cloud

### –í–∞—Ä–∏–∞–Ω—Ç 2: Cloud-Native Observability (Loki + Prometheus + Grafana)

**–û–ø–∏—Å–∞–Ω–∏–µ**: –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å Grafana Loki –¥–ª—è –ª–æ–≥–æ–≤ + Prometheus –¥–ª—è –º–µ—Ç—Ä–∏–∫ –≤ unified Grafana experience.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤**:
```
Applications/Services
       ‚Üì
   Promtail (Log Collection)
       ‚Üì
   Loki (Log Storage)
       ‚Üì
   Grafana (Unified Visualization)
       ‚Üë
   Prometheus (Metrics)
       ‚Üë
   Applications/Services
```

**Technology Stack**:
- **Logging**: Grafana Loki + Promtail
- **Metrics**: Prometheus + Grafana
- **Tracing**: Tempo (Grafana's tracing solution)
- **Alerting**: Grafana Alerting + AlertManager
- **Error Tracking**: Integrated —Å Grafana ecosystem

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- Unified experience –≤ single Grafana interface
- Cost-effective storage —Å Loki's compression
- Cloud-native design —Å horizontal scaling
- LogQL query language –¥–ª—è powerful log analysis
- Excellent Kubernetes integration
- Lower resource footprint —á–µ–º ELK

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**:
- Newer ecosystem —Å potentially less community support
- Limited full-text search capabilities compared to Elasticsearch
- Fewer third-party integrations
- Learning curve –¥–ª—è LogQL
- Still evolving feature set

### –í–∞—Ä–∏–∞–Ω—Ç 3: Hybrid Multi-Stack Observability

**–û–ø–∏—Å–∞–Ω–∏–µ**: –ö–æ–º–±–∏–Ω–∞—Ü–∏—è –ª—É—á—à–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —ç–∫–æ—Å–∏—Å—Ç–µ–º –¥–ª—è optimal coverage –≤—Å–µ—Ö observability needs.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤**:
```
Applications/Services
       ‚Üì
   Vector (Unified Data Pipeline)
       ‚Üì
   ‚îú‚îÄ Loki (Application Logs)
   ‚îú‚îÄ Elasticsearch (Search & Analytics)
   ‚îú‚îÄ ClickHouse (High-Volume Metrics)
   ‚îî‚îÄ S3 (Long-term Storage)
       ‚Üì
   Grafana (Primary Dashboards)
   Kibana (Deep Log Analysis)
   Sentry (Error Tracking)
   DataDog/NewRelic (APM)
```

**Technology Stack**:
- **Log Pipeline**: Vector –¥–ª—è data routing
- **Log Storage**: Loki (operational) + Elasticsearch (analytical)
- **Metrics**: Prometheus + ClickHouse –¥–ª—è high-cardinality data
- **Dashboards**: Grafana (primary) + Kibana (specialized)
- **APM**: Jaeger + Sentry + optional cloud APM
- **Infrastructure**: Kubernetes + Helm charts

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- Best-of-breed tools –¥–ª—è specific use cases
- Maximum flexibility –∏ customization
- Optimal performance –¥–ª—è different data types
- Redundancy –∏ vendor diversification
- Advanced analytics capabilities
- Future-proof architecture

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**:
- Highest complexity –¥–ª—è setup –∏ maintenance
- Multiple tools to learn –∏ maintain
- Potential data consistency issues
- Higher operational overhead
- Complex alerting coordination
- Cost complexity

## –ê–Ω–∞–ª–∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤

### –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:
1. **Setup Complexity** - —Å–ª–æ–∂–Ω–æ—Å—Ç—å initial deployment
2. **Operational Overhead** - daily maintenance requirements
3. **Performance** - query speed –∏ resource efficiency
4. **Scalability** - ability to handle growth
5. **Cost Efficiency** - total cost of ownership
6. **Feature Completeness** - coverage of all requirements

### –û—Ü–µ–Ω–∫–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:

| –ö—Ä–∏—Ç–µ—Ä–∏–π | ELK + Prometheus | Loki + Prometheus | Hybrid Multi-Stack |
|----------|------------------|-------------------|-------------------|
| **Setup Complexity** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| **Operational Overhead** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| **Performance** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Scalability** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Cost Efficiency** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Feature Completeness** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

## –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ

### **–í—ã–±–æ—Ä: Cloud-Native Observability (Loki + Prometheus + Grafana) —Å —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ Hybrid**

**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ**:
1. **Modern Architecture**: Cloud-native design better suited –¥–ª—è microservices
2. **Cost Efficiency**: Significant savings compared to ELK stack
3. **Unified Experience**: Single pane of glass –≤ Grafana
4. **Kubernetes Native**: Excellent integration —Å container orchestration
5. **Scalability**: Horizontal scaling capabilities
6. **Strategic Addition**: Selective hybrid components –≥–¥–µ needed (Sentry for errors)

### Observability Architecture Design:

```mermaid
graph TB
    subgraph "Application Layer"
        FastAPI[FastAPI Services<br/>Auth, Game, Stats, Friends, Templates]
        React[React App<br/>Telegram Mini App]
        RabbitMQ[RabbitMQ<br/>Message Broker]
        PostgreSQL[PostgreSQL<br/>Databases]
        Redis[Redis<br/>Cache & Sessions]
    end
    
    subgraph "Data Collection Layer"
        Promtail[Promtail<br/>Log Collection]
        PrometheusAgent[Prometheus<br/>Metrics Collection]
        Tempo[Tempo<br/>Trace Collection]
        SentrySDK[Sentry SDK<br/>Error Tracking]
    end
    
    subgraph "Storage Layer"
        Loki[Loki<br/>Log Storage & Indexing]
        PrometheusDB[Prometheus TSDB<br/>Metrics Storage]
        TempoStorage[Tempo<br/>Trace Storage]
        SentryCloud[Sentry Cloud<br/>Error Storage]
    end
    
    subgraph "Visualization & Alerting"
        Grafana[Grafana<br/>Dashboards & Alerts]
        AlertManager[AlertManager<br/>Alert Routing]
        SentryUI[Sentry Dashboard<br/>Error Analysis]
    end
    
    subgraph "External Integrations"
        Slack[Slack<br/>Notifications]
        Email[Email<br/>Alerts]
        Telegram[Telegram Bot<br/>Notifications]
        PagerDuty[PagerDuty<br/>Incident Management]
    end
    
    FastAPI --> Promtail
    React --> Promtail
    RabbitMQ --> PrometheusAgent
    PostgreSQL --> PrometheusAgent
    Redis --> PrometheusAgent
    
    FastAPI --> PrometheusAgent
    React --> PrometheusAgent
    
    FastAPI --> Tempo
    React --> Tempo
    
    FastAPI --> SentrySDK
    React --> SentrySDK
    
    Promtail --> Loki
    PrometheusAgent --> PrometheusDB
    Tempo --> TempoStorage
    SentrySDK --> SentryCloud
    
    Loki --> Grafana
    PrometheusDB --> Grafana
    TempoStorage --> Grafana
    
    Grafana --> AlertManager
    AlertManager --> Slack
    AlertManager --> Email
    AlertManager --> Telegram
    AlertManager --> PagerDuty
    
    SentryCloud --> SentryUI
    
    style FastAPI fill:#3b82f6,color:white
    style React fill:#06b6d4,color:white
    style Grafana fill:#f59e0b,color:white
    style Loki fill:#10b981,color:white
    style PrometheusDB fill:#ef4444,color:white
    style SentryCloud fill:#8b5cf6,color:white
```

## Implementation Guidelines

### 1. Logging Strategy

**Structured Logging Implementation**:
```python
# shared/logging/logger.py
import logging
import json
import time
from typing import Dict, Any, Optional
from contextlib import contextmanager
from contextvars import ContextVar
from loguru import logger
import structlog

# Context variables for request tracking
request_id_var: ContextVar[str] = ContextVar('request_id', default='')
user_id_var: ContextVar[str] = ContextVar('user_id', default='')
session_id_var: ContextVar[str] = ContextVar('session_id', default='')

class StructuredLogger:
    def __init__(self, service_name: str, version: str):
        self.service_name = service_name
        self.version = version
        self.setup_structlog()
    
    def setup_structlog(self):
        structlog.configure(
            processors=[
                structlog.contextvars.merge_contextvars,
                structlog.processors.add_log_level,
                structlog.processors.StackInfoRenderer(),
                structlog.dev.set_exc_info,
                self.add_service_context,
                structlog.processors.JSONRenderer()
            ],
            wrapper_class=structlog.stdlib.BoundLogger,
            logger_factory=structlog.stdlib.LoggerFactory(),
            cache_logger_on_first_use=True,
        )
    
    def add_service_context(self, logger, method_name, event_dict):
        event_dict.update({
            'service': self.service_name,
            'version': self.version,
            'timestamp': time.time(),
            'request_id': request_id_var.get(),
            'user_id': user_id_var.get(),
            'session_id': session_id_var.get()
        })
        return event_dict
    
    @contextmanager
    def request_context(self, request_id: str, user_id: Optional[str] = None, 
                       session_id: Optional[str] = None):
        tokens = [
            request_id_var.set(request_id),
            user_id_var.set(user_id or ''),
            session_id_var.set(session_id or '')
        ]
        try:
            yield
        finally:
            for token in tokens:
                token.var.set(token.old_value)

# Application logger setup
logger_instance = StructuredLogger("game-service", "1.0.0")
app_logger = structlog.get_logger()

# Usage examples
async def create_game_session(user_id: str, game_data: dict):
    request_id = str(uuid.uuid4())
    
    with logger_instance.request_context(request_id, user_id):
        app_logger.info(
            "Creating game session",
            game_type=game_data.get('type'),
            max_players=game_data.get('max_players'),
            user_action="create_session"
        )
        
        try:
            session = await game_service.create_session(game_data)
            
            app_logger.info(
                "Game session created successfully",
                session_id=session.id,
                game_type=session.game_type,
                duration_ms=elapsed_time,
                user_action="session_created"
            )
            
            return session
            
        except Exception as e:
            app_logger.error(
                "Failed to create game session",
                error=str(e),
                error_type=type(e).__name__,
                user_action="session_creation_failed",
                exc_info=True
            )
            raise

# Business event logging
class BusinessEventLogger:
    @staticmethod
    def log_game_event(event_type: str, session_id: str, player_id: str, 
                      event_data: Dict[str, Any]):
        app_logger.info(
            "Game event occurred",
            event_type=event_type,
            session_id=session_id,
            player_id=player_id,
            event_data=event_data,
            category="business_event"
        )
    
    @staticmethod
    def log_user_action(action: str, user_id: str, metadata: Dict[str, Any]):
        app_logger.info(
            "User action performed",
            action=action,
            user_id=user_id,
            metadata=metadata,
            category="user_action"
        )
    
    @staticmethod
    def log_system_metric(metric_name: str, value: float, 
                         labels: Dict[str, str]):
        app_logger.info(
            "System metric recorded",
            metric_name=metric_name,
            metric_value=value,
            labels=labels,
            category="system_metric"
        )
```

**FastAPI Middleware –¥–ª—è Request Logging**:
```python
# middleware/logging_middleware.py
import time
import uuid
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response

class RequestLoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        request_id = str(uuid.uuid4())
        
        # Add request ID to headers
        request.state.request_id = request_id
        
        # Extract user info if available
        user_id = None
        if hasattr(request.state, 'user'):
            user_id = request.state.user.id
        
        with logger_instance.request_context(request_id, user_id):
            # Log request start
            app_logger.info(
                "Request started",
                method=request.method,
                url=str(request.url),
                user_agent=request.headers.get('user-agent'),
                client_ip=request.client.host,
                category="http_request"
            )
            
            try:
                response = await call_next(request)
                duration = time.time() - start_time
                
                # Log successful response
                app_logger.info(
                    "Request completed",
                    method=request.method,
                    url=str(request.url),
                    status_code=response.status_code,
                    duration_ms=round(duration * 1000, 2),
                    category="http_response"
                )
                
                return response
                
            except Exception as e:
                duration = time.time() - start_time
                
                # Log error response
                app_logger.error(
                    "Request failed",
                    method=request.method,
                    url=str(request.url),
                    error=str(e),
                    error_type=type(e).__name__,
                    duration_ms=round(duration * 1000, 2),
                    category="http_error",
                    exc_info=True
                )
                
                raise
```

### 2. Metrics Collection

**Prometheus Metrics –¥–ª—è FastAPI**:
```python
# monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, Info
import time
from functools import wraps
from typing import Dict, Any

class AppMetrics:
    def __init__(self, service_name: str):
        self.service_name = service_name
        
        # HTTP metrics
        self.http_requests_total = Counter(
            'http_requests_total',
            'Total HTTP requests',
            ['method', 'endpoint', 'status_code', 'service']
        )
        
        self.http_request_duration = Histogram(
            'http_request_duration_seconds',
            'HTTP request duration',
            ['method', 'endpoint', 'service'],
            buckets=(0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0)
        )
        
        # Business metrics
        self.active_game_sessions = Gauge(
            'active_game_sessions_total',
            'Number of active game sessions',
            ['game_type', 'service']
        )
        
        self.game_events_total = Counter(
            'game_events_total',
            'Total game events',
            ['event_type', 'game_type', 'service']
        )
        
        self.user_actions_total = Counter(
            'user_actions_total',
            'Total user actions',
            ['action_type', 'service']
        )
        
        # Database metrics
        self.db_connections_active = Gauge(
            'db_connections_active',
            'Active database connections',
            ['database', 'service']
        )
        
        self.db_query_duration = Histogram(
            'db_query_duration_seconds',
            'Database query duration',
            ['query_type', 'table', 'service'],
            buckets=(0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0)
        )
        
        # Cache metrics
        self.cache_hits_total = Counter(
            'cache_hits_total',
            'Total cache hits',
            ['cache_type', 'service']
        )
        
        self.cache_misses_total = Counter(
            'cache_misses_total',
            'Total cache misses',
            ['cache_type', 'service']
        )
        
        # System metrics
        self.memory_usage_bytes = Gauge(
            'memory_usage_bytes',
            'Memory usage in bytes',
            ['service']
        )
        
        # WebSocket metrics
        self.websocket_connections_active = Gauge(
            'websocket_connections_active',
            'Active WebSocket connections',
            ['service']
        )
        
        self.websocket_messages_total = Counter(
            'websocket_messages_total',
            'Total WebSocket messages',
            ['direction', 'message_type', 'service']
        )
    
    def track_http_request(self, method: str, endpoint: str):
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                start_time = time.time()
                status_code = 200
                
                try:
                    result = await func(*args, **kwargs)
                    return result
                except Exception as e:
                    status_code = getattr(e, 'status_code', 500)
                    raise
                finally:
                    duration = time.time() - start_time
                    
                    self.http_requests_total.labels(
                        method=method,
                        endpoint=endpoint,
                        status_code=status_code,
                        service=self.service_name
                    ).inc()
                    
                    self.http_request_duration.labels(
                        method=method,
                        endpoint=endpoint,
                        service=self.service_name
                    ).observe(duration)
            
            return wrapper
        return decorator
    
    def track_business_event(self, event_type: str, game_type: str = None):
        self.game_events_total.labels(
            event_type=event_type,
            game_type=game_type or 'unknown',
            service=self.service_name
        ).inc()
    
    def track_user_action(self, action_type: str):
        self.user_actions_total.labels(
            action_type=action_type,
            service=self.service_name
        ).inc()
    
    def update_active_sessions(self, game_type: str, count: int):
        self.active_game_sessions.labels(
            game_type=game_type,
            service=self.service_name
        ).set(count)
    
    def track_db_query(self, query_type: str, table: str):
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                start_time = time.time()
                
                try:
                    result = await func(*args, **kwargs)
                    return result
                finally:
                    duration = time.time() - start_time
                    self.db_query_duration.labels(
                        query_type=query_type,
                        table=table,
                        service=self.service_name
                    ).observe(duration)
            
            return wrapper
        return decorator

# Global metrics instance
metrics = AppMetrics("game-service")

# Usage examples
@metrics.track_http_request("POST", "/sessions")
async def create_session(session_data: CreateSessionRequest):
    metrics.track_user_action("create_session")
    
    # Business logic here
    session = await session_service.create(session_data)
    
    metrics.track_business_event("session_created", session.game_type)
    metrics.update_active_sessions(session.game_type, 
                                  await session_service.count_active())
    
    return session

@metrics.track_db_query("INSERT", "game_sessions")
async def save_session_to_db(session_data: dict):
    # Database operation
    pass
```

**React App Metrics**:
```typescript
// src/shared/lib/monitoring/metrics.ts
interface MetricEvent {
  name: string;
  value?: number;
  labels?: Record<string, string>;
  timestamp?: number;
}

class BrowserMetrics {
  private endpoint: string;
  private buffer: MetricEvent[] = [];
  private flushInterval: number = 30000; // 30 seconds
  
  constructor(endpoint: string) {
    this.endpoint = endpoint;
    this.startPeriodicFlush();
    this.setupPerformanceObserver();
  }
  
  // User interaction metrics
  trackUserAction(action: string, metadata?: Record<string, any>) {
    this.addMetric({
      name: 'user_action_total',
      value: 1,
      labels: {
        action,
        page: window.location.pathname,
        ...metadata
      }
    });
  }
  
  // Page performance metrics
  trackPageLoad(pageName: string, loadTime: number) {
    this.addMetric({
      name: 'page_load_duration_ms',
      value: loadTime,
      labels: { page: pageName }
    });
  }
  
  // API call metrics
  trackApiCall(endpoint: string, method: string, duration: number, 
              statusCode: number) {
    this.addMetric({
      name: 'api_request_duration_ms',
      value: duration,
      labels: { endpoint, method, status_code: statusCode.toString() }
    });
  }
  
  // Game-specific metrics
  trackGameEvent(eventType: string, gameType: string, sessionId: string) {
    this.addMetric({
      name: 'game_event_total',
      value: 1,
      labels: { event_type: eventType, game_type: gameType, session_id: sessionId }
    });
  }
  
  // Error tracking
  trackError(error: Error, context?: Record<string, any>) {
    this.addMetric({
      name: 'frontend_error_total',
      value: 1,
      labels: {
        error_type: error.name,
        error_message: error.message.substring(0, 100),
        page: window.location.pathname,
        ...context
      }
    });
  }
  
  private addMetric(metric: MetricEvent) {
    this.buffer.push({
      ...metric,
      timestamp: Date.now()
    });
    
    // Flush if buffer is getting large
    if (this.buffer.length >= 100) {
      this.flush();
    }
  }
  
  private async flush() {
    if (this.buffer.length === 0) return;
    
    const metricsToSend = [...this.buffer];
    this.buffer = [];
    
    try {
      await fetch(this.endpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ metrics: metricsToSend })
      });
    } catch (error) {
      console.error('Failed to send metrics:', error);
      // Re-add metrics to buffer for retry
      this.buffer.unshift(...metricsToSend);
    }
  }
  
  private startPeriodicFlush() {
    setInterval(() => this.flush(), this.flushInterval);
  }
  
  private setupPerformanceObserver() {
    if ('PerformanceObserver' in window) {
      const observer = new PerformanceObserver((list) => {
        for (const entry of list.getEntries()) {
          if (entry.entryType === 'navigation') {
            this.trackPageLoad(
              window.location.pathname,
              entry.duration
            );
          }
        }
      });
      
      observer.observe({ entryTypes: ['navigation'] });
    }
  }
}

export const metrics = new BrowserMetrics('/api/metrics');

// React hook for metrics
export const useMetrics = () => {
  const trackUserAction = useCallback((action: string, metadata?: Record<string, any>) => {
    metrics.trackUserAction(action, metadata);
  }, []);
  
  const trackGameEvent = useCallback((eventType: string, gameType: string, sessionId: string) => {
    metrics.trackGameEvent(eventType, gameType, sessionId);
  }, []);
  
  const trackError = useCallback((error: Error, context?: Record<string, any>) => {
    metrics.trackError(error, context);
  }, []);
  
  return {
    trackUserAction,
    trackGameEvent,
    trackError
  };
};

// Usage in components
const GameRoom = ({ sessionId, gameType }: GameRoomProps) => {
  const { trackUserAction, trackGameEvent } = useMetrics();
  
  const handleBallClick = (ballId: string) => {
    trackUserAction('ball_clicked', { ball_id: ballId, session_id: sessionId });
    trackGameEvent('ball_potted', gameType, sessionId);
    
    // Game logic here
  };
  
  return (
    <div className="game-room">
      <BilliardTable onBallClick={handleBallClick} />
    </div>
  );
};
```

### 3. Alerting Rules

**Prometheus Alert Rules**:
```yaml
# monitoring/prometheus/alert-rules.yml
groups:
  - name: application.rules
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: (rate(http_requests_total{status_code=~"5.."}[5m]) / rate(http_requests_total[5m])) * 100 > 5
        for: 2m
        labels:
          severity: warning
          service: "{{ $labels.service }}"
        annotations:
          summary: "High error rate detected"
          description: "Service {{ $labels.service }} has error rate of {{ $value }}% for more than 2 minutes"
      
      # High response time
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 3m
        labels:
          severity: warning
          service: "{{ $labels.service }}"
        annotations:
          summary: "High response time detected"
          description: "Service {{ $labels.service }} 95th percentile response time is {{ $value }}s"
      
      # Service down
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          service: "{{ $labels.instance }}"
        annotations:
          summary: "Service is down"
          description: "Service {{ $labels.instance }} has been down for more than 1 minute"
      
      # Database connection issues
      - alert: DatabaseConnectionPool
        expr: db_connections_active / db_connections_max > 0.8
        for: 2m
        labels:
          severity: warning
          service: "{{ $labels.service }}"
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "Service {{ $labels.service }} using {{ $value }}% of database connections"
      
      # High memory usage
      - alert: HighMemoryUsage
        expr: (memory_usage_bytes / memory_limit_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: "{{ $labels.service }}"
        annotations:
          summary: "High memory usage"
          description: "Service {{ $labels.service }} memory usage is {{ $value }}%"
      
      # Game-specific alerts
      - alert: GameSessionCreationFailure
        expr: rate(game_events_total{event_type="session_creation_failed"}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
          team: game
        annotations:
          summary: "High game session creation failure rate"
          description: "Game session creation failing at {{ $value }} per second"
      
      # Business metrics alerts
      - alert: LowUserActivity
        expr: rate(user_actions_total[10m]) < 10
        for: 5m
        labels:
          severity: info
          team: product
        annotations:
          summary: "Low user activity detected"
          description: "User activity rate dropped to {{ $value }} actions per second"

  - name: infrastructure.rules
    rules:
      # Disk space
      - alert: DiskSpaceLow
        expr: (disk_free_bytes / disk_total_bytes) * 100 < 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space"
          description: "Disk space on {{ $labels.instance }} is {{ $value }}% free"
      
      # Network issues
      - alert: HighNetworkErrors
        expr: rate(network_errors_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High network error rate"
          description: "Network errors at {{ $value }} per second on {{ $labels.instance }}"

  - name: security.rules
    rules:
      # Authentication failures
      - alert: HighAuthFailureRate
        expr: rate(auth_failures_total[5m]) > 5
        for: 1m
        labels:
          severity: critical
          team: security
        annotations:
          summary: "High authentication failure rate"
          description: "Authentication failures at {{ $value }} per second - possible brute force attack"
      
      # Suspicious user activity
      - alert: SuspiciousUserActivity
        expr: rate(user_actions_total{action_type="suspicious"}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "Suspicious user activity detected"
          description: "Suspicious activities detected at {{ $value }} per second"
```

**AlertManager Configuration**:
```yaml
# monitoring/alertmanager/alertmanager.yml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@artelbilliards.com'
  smtp_auth_username: 'alerts@artelbilliards.com'
  smtp_auth_password: 'your-app-password'

route:
  group_by: ['alertname', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 5s
      repeat_interval: 10m
    
    - match:
        team: security
      receiver: 'security-team'
      group_wait: 5s
      repeat_interval: 5m
    
    - match:
        team: game
      receiver: 'game-team'
    
    - match:
        team: product
      receiver: 'product-team'

receivers:
  - name: 'default'
    email_configs:
      - to: 'dev-team@artelbilliards.com'
        subject: 'ArtelBilliards Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Severity: {{ .Labels.severity }}
          {{ end }}

  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@artelbilliards.com'
        subject: 'CRITICAL: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: 'https://hooks.slack.com/your-webhook-url'
        channel: '#alerts-critical'
        title: 'Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          {{ end }}
    
    webhook_configs:
      - url: 'https://api.telegram.org/bot<token>/sendMessage'
        send_resolved: true

  - name: 'security-team'
    email_configs:
      - to: 'security@artelbilliards.com'
        subject: 'SECURITY ALERT: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: 'https://hooks.slack.com/your-security-webhook'
        channel: '#security-alerts'

  - name: 'game-team'
    email_configs:
      - to: 'game-dev@artelbilliards.com'
        subject: 'Game Service Alert: {{ .GroupLabels.alertname }}'

  - name: 'product-team'
    email_configs:
      - to: 'product@artelbilliards.com'
        subject: 'Product Metrics Alert: {{ .GroupLabels.alertname }}'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'service']
```

### 4. Grafana Dashboards

**Service Overview Dashboard**:
```json
{
  "dashboard": {
    "id": null,
    "title": "ArtelBilliards Service Overview",
    "panels": [
      {
        "title": "Service Health",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=~\".*artel.*\"}",
            "legendFormat": "{{ instance }}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "mappings": [
              { "value": 1, "text": "UP", "color": "green" },
              { "value": 0, "text": "DOWN", "color": "red" }
            ]
          }
        }
      },
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m])) by (service)",
            "legendFormat": "{{ service }}"
          }
        ]
      },
      {
        "title": "Response Time P95",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service))",
            "legendFormat": "{{ service }}"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status_code=~\"5..\"}[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service) * 100",
            "legendFormat": "{{ service }}"
          }
        ]
      },
      {
        "title": "Active Game Sessions",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(active_game_sessions_total) by (game_type)",
            "legendFormat": "{{ game_type }}"
          }
        ]
      },
      {
        "title": "Recent Logs",
        "type": "logs",
        "targets": [
          {
            "expr": "{service=~\".*artel.*\"} |= \"ERROR\" | json",
            "refId": "A"
          }
        ]
      }
    ]
  }
}
```

**Business Metrics Dashboard**:
```json
{
  "dashboard": {
    "title": "ArtelBilliards Business Metrics",
    "panels": [
      {
        "title": "User Registrations (Daily)",
        "type": "graph",
        "targets": [
          {
            "expr": "increase(user_actions_total{action_type=\"user_registered\"}[24h])",
            "legendFormat": "New Users"
          }
        ]
      },
      {
        "title": "Game Sessions Created",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(game_events_total{event_type=\"session_created\"}[5m])) by (game_type)",
            "legendFormat": "{{ game_type }}"
          }
        ]
      },
      {
        "title": "Average Session Duration",
        "type": "stat",
        "targets": [
          {
            "expr": "avg(game_session_duration_minutes)",
            "legendFormat": "Minutes"
          }
        ]
      },
      {
        "title": "Revenue by Game Type",
        "type": "piechart",
        "targets": [
          {
            "expr": "sum(game_revenue_rubles) by (game_type)",
            "legendFormat": "{{ game_type }}"
          }
        ]
      },
      {
        "title": "User Activity Heatmap",
        "type": "heatmap",
        "targets": [
          {
            "expr": "sum(rate(user_actions_total[1h])) by (hour)",
            "format": "heatmap"
          }
        ]
      }
    ]
  }
}
```

**Infrastructure Dashboard**:
```json
{
  "dashboard": {
    "title": "Infrastructure Monitoring",
    "panels": [
      {
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "{{ instance }}"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
            "legendFormat": "{{ instance }}"
          }
        ]
      },
      {
        "title": "Database Connections",
        "type": "graph",
        "targets": [
          {
            "expr": "db_connections_active",
            "legendFormat": "{{ database }} - {{ service }}"
          }
        ]
      },
      {
        "title": "WebSocket Connections",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(websocket_connections_active)",
            "legendFormat": "Active Connections"
          }
        ]
      }
    ]
  }
}
```

### 5. Log Analysis & Search

**Loki Query Examples**:
```logql
# Error logs across all services
{service=~".*artel.*"} |= "ERROR" | json | line_format "{{.timestamp}} [{{.level}}] {{.service}}: {{.message}}"

# Game session creation logs
{service="game-service"} | json | user_action="create_session" | line_format "User {{.user_id}} created {{.game_type}} session {{.session_id}}"

# Slow API requests
{service=~".*artel.*"} | json | duration_ms > 1000 | line_format "SLOW: {{.method}} {{.url}} took {{.duration_ms}}ms"

# Authentication failures
{service="auth-service"} | json | category="auth_failure" | line_format "Auth failed for {{.user_id}} from {{.client_ip}}: {{.error}}"

# Business events for analytics
{service=~".*artel.*"} | json | category="business_event" | line_format "{{.event_type}}: {{.event_data}}"

# Security monitoring
{service=~".*artel.*"} | json | category="security" | line_format "SECURITY: {{.event_type}} - {{.details}}"

# Database query performance
{service=~".*artel.*"} | json | category="db_query" | duration_ms > 100 | line_format "SLOW DB: {{.query_type}} on {{.table}} took {{.duration_ms}}ms"

# WebSocket connection issues
{service="game-service"} | json | websocket="true" | line_format "WS: {{.event}} for session {{.session_id}}"
```

**Log Parsing Rules**:
```yaml
# promtail/config.yml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: containers
    static_configs:
      - targets:
          - localhost
        labels:
          job: containerlogs
          __path__: /var/log/containers/*log
    
    pipeline_stages:
      # Parse JSON logs
      - json:
          expressions:
            timestamp: timestamp
            level: level
            service: service
            message: message
            request_id: request_id
            user_id: user_id
            session_id: session_id
            category: category
      
      # Extract request info for HTTP logs
      - regex:
          expression: '(?P<method>GET|POST|PUT|DELETE) (?P<path>/[^\s]*)'
          source: message
      
      # Parse duration from performance logs
      - regex:
          expression: 'duration=(?P<duration_ms>\d+)ms'
          source: message
      
      # Add labels
      - labels:
          service:
          level:
          category:
          method:
          request_id:
      
      # Template for output format
      - template:
          source: output
          template: '{{ .timestamp }} [{{ .level }}] {{ .service }}: {{ .message }}'
      
      # Drop debug logs in production
      - drop:
          expression: '.*level=debug.*'
          drop_counter_reason: debug_logs_dropped

  - job_name: syslog
    static_configs:
      - targets:
          - localhost
        labels:
          job: syslog
          __path__: /var/log/syslog
    
    pipeline_stages:
      - regex:
          expression: '^(?P<timestamp>\S+\s+\d+\s+\d+:\d+:\d+)\s+(?P<hostname>\S+)\s+(?P<app>\S+):\s+(?P<message>.*)$'
      
      - timestamp:
          source: timestamp
          format: 'Jan 2 15:04:05'
      
      - labels:
          hostname:
          app:
```

### 6. Error Tracking Integration

**Sentry Configuration**:
```python
# shared/monitoring/sentry_config.py
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.sqlalchemy import SqlalchemyIntegration
from sentry_sdk.integrations.redis import RedisIntegration
from sentry_sdk.integrations.logging import LoggingIntegration
import logging

def setup_sentry(service_name: str, environment: str, dsn: str):
    sentry_logging = LoggingIntegration(
        level=logging.INFO,        # Capture info and above as breadcrumbs
        event_level=logging.ERROR  # Send errors as events
    )
    
    sentry_sdk.init(
        dsn=dsn,
        environment=environment,
        integrations=[
            FastApiIntegration(),
            SqlalchemyIntegration(),
            RedisIntegration(),
            sentry_logging,
        ],
        traces_sample_rate=0.1,  # Performance monitoring
        profiles_sample_rate=0.1,  # Profiling
        send_default_pii=False,  # Don't send PII
        before_send=filter_sensitive_data,
        before_send_transaction=filter_transactions,
        release=f"{service_name}@{get_version()}",
        server_name=service_name,
    )
    
    # Set service context
    sentry_sdk.set_tag("service", service_name)
    sentry_sdk.set_context("service_info", {
        "name": service_name,
        "environment": environment,
        "version": get_version()
    })

def filter_sensitive_data(event, hint):
    """Filter out sensitive information from Sentry events"""
    # Remove sensitive headers
    if 'request' in event:
        headers = event['request'].get('headers', {})
        sensitive_headers = ['authorization', 'cookie', 'x-api-key']
        for header in sensitive_headers:
            if header in headers:
                headers[header] = '[Filtered]'
    
    # Remove sensitive form data
    if 'request' in event and 'data' in event['request']:
        data = event['request']['data']
        if isinstance(data, dict):
            sensitive_fields = ['password', 'token', 'secret', 'key']
            for field in sensitive_fields:
                if field in data:
                    data[field] = '[Filtered]'
    
    return event

def filter_transactions(event, hint):
    """Filter performance transactions"""
    # Don't track health check endpoints
    if event.get('transaction', '').endswith('/health'):
        return None
    
    # Don't track static file requests
    if event.get('transaction', '').startswith('/static/'):
        return None
    
    return event

# Custom error capture
class ErrorTracker:
    @staticmethod
    def capture_game_error(error: Exception, session_id: str, 
                          user_id: str, game_context: dict):
        with sentry_sdk.push_scope() as scope:
            scope.set_tag("error_type", "game_error")
            scope.set_context("game", {
                "session_id": session_id,
                "user_id": user_id,
                "game_type": game_context.get("type"),
                "players_count": game_context.get("players_count"),
                "game_state": game_context.get("state")
            })
            scope.set_level("error")
            sentry_sdk.capture_exception(error)
    
    @staticmethod
    def capture_business_metric(metric_name: str, value: float, 
                               context: dict):
        sentry_sdk.set_measurement(metric_name, value)
        sentry_sdk.add_breadcrumb(
            message=f"Business metric: {metric_name} = {value}",
            category="business",
            level="info",
            data=context
        )
    
    @staticmethod
    def capture_performance_issue(operation: str, duration: float, 
                                 threshold: float, context: dict):
        if duration > threshold:
            with sentry_sdk.push_scope() as scope:
                scope.set_tag("performance_issue", operation)
                scope.set_context("performance", {
                    "operation": operation,
                    "duration_ms": duration,
                    "threshold_ms": threshold,
                    **context
                })
                sentry_sdk.capture_message(
                    f"Performance issue: {operation} took {duration}ms",
                    level="warning"
                )
```

**React Sentry Integration**:
```typescript
// src/shared/lib/monitoring/sentry.ts
import * as Sentry from '@sentry/react';
import { BrowserTracing } from '@sentry/tracing';

export const initSentry = () => {
  Sentry.init({
    dsn: process.env.REACT_APP_SENTRY_DSN,
    environment: process.env.NODE_ENV,
    integrations: [
      new BrowserTracing(),
      new Sentry.Replay({
        maskAllText: true,
        blockAllMedia: true,
      }),
    ],
    tracesSampleRate: 0.1,
    replaysSessionSampleRate: 0.1,
    replaysOnErrorSampleRate: 1.0,
    beforeSend: (event, hint) => {
      // Filter out non-critical errors
      if (event.exception) {
        const error = hint.originalException;
        if (error instanceof TypeError && error.message.includes('Network request failed')) {
          return null; // Don't send network errors
        }
      }
      return event;
    },
  });
  
  // Set user context when available
  Sentry.setContext('app', {
    name: 'ArtelBilliards',
    version: process.env.REACT_APP_VERSION,
    platform: 'telegram-mini-app'
  });
};

// Error boundary with Sentry
export const SentryErrorBoundary = Sentry.withErrorBoundary(
  ({ children }: { children: React.ReactNode }) => children,
  {
    fallback: ({ error, resetError }) => (
      <div className="error-boundary">
        <h2>Something went wrong</h2>
        <details>
          <summary>Error details</summary>
          <pre>{error.message}</pre>
        </details>
        <button onClick={resetError}>Try again</button>
      </div>
    ),
    beforeCapture: (scope, error, errorInfo) => {
      scope.setTag('errorBoundary', true);
      scope.setContext('errorInfo', errorInfo);
    },
  }
);

// Custom hooks for error tracking
export const useErrorTracking = () => {
  const captureGameError = useCallback((error: Error, gameContext: any) => {
    Sentry.withScope((scope) => {
      scope.setTag('errorType', 'game');
      scope.setContext('game', gameContext);
      Sentry.captureException(error);
    });
  }, []);
  
  const captureUserAction = useCallback((action: string, outcome: 'success' | 'error', metadata?: any) => {
    Sentry.addBreadcrumb({
      message: `User action: ${action}`,
      category: 'user',
      level: outcome === 'success' ? 'info' : 'error',
      data: { action, outcome, ...metadata },
    });
  }, []);
  
  return { captureGameError, captureUserAction };
};
```

### 7. Performance Monitoring

**Distributed Tracing Setup**:
```python
# shared/monitoring/tracing.py
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
from opentelemetry.instrumentation.redis import RedisInstrumentor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
import asyncio
from functools import wraps

def setup_tracing(service_name: str, jaeger_endpoint: str):
    # Create tracer provider
    trace.set_tracer_provider(TracerProvider())
    tracer = trace.get_tracer(service_name)
    
    # Configure Jaeger exporter
    jaeger_exporter = JaegerExporter(
        agent_host_name="jaeger",
        agent_port=14268,
        collector_endpoint=jaeger_endpoint,
    )
    
    # Add span processor
    span_processor = BatchSpanProcessor(jaeger_exporter)
    trace.get_tracer_provider().add_span_processor(span_processor)
    
    # Auto-instrument libraries
    FastAPIInstrumentor.instrument()
    SQLAlchemyInstrumentor.instrument()
    RedisInstrumentor.instrument()
    RequestsInstrumentor.instrument()
    
    return tracer

# Custom tracing decorators
def trace_function(operation_name: str):
    def decorator(func):
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            tracer = trace.get_tracer(__name__)
            with tracer.start_as_current_span(operation_name) as span:
                # Add function metadata
                span.set_attribute("function.name", func.__name__)
                span.set_attribute("function.module", func.__module__)
                
                try:
                    result = await func(*args, **kwargs)
                    span.set_attribute("function.result", "success")
                    return result
                except Exception as e:
                    span.set_attribute("function.result", "error")
                    span.set_attribute("error.type", type(e).__name__)
                    span.set_attribute("error.message", str(e))
                    raise
        
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            tracer = trace.get_tracer(__name__)
            with tracer.start_as_current_span(operation_name) as span:
                span.set_attribute("function.name", func.__name__)
                span.set_attribute("function.module", func.__module__)
                
                try:
                    result = func(*args, **kwargs)
                    span.set_attribute("function.result", "success")
                    return result
                except Exception as e:
                    span.set_attribute("function.result", "error")
                    span.set_attribute("error.type", type(e).__name__)
                    span.set_attribute("error.message", str(e))
                    raise
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator

# Game-specific tracing
class GameTracer:
    def __init__(self, tracer):
        self.tracer = tracer
    
    def trace_game_session(self, session_id: str, game_type: str):
        span = self.tracer.start_span("game.session")
        span.set_attribute("game.session_id", session_id)
        span.set_attribute("game.type", game_type)
        return span
    
    def trace_game_event(self, event_type: str, player_id: str, session_id: str):
        span = self.tracer.start_span("game.event")
        span.set_attribute("game.event_type", event_type)
        span.set_attribute("game.player_id", player_id)
        span.set_attribute("game.session_id", session_id)
        return span
    
    def trace_score_calculation(self, calculation_type: str, session_id: str):
        span = self.tracer.start_span("game.score_calculation")
        span.set_attribute("game.calculation_type", calculation_type)
        span.set_attribute("game.session_id", session_id)
        return span

# Usage examples
@trace_function("create_game_session")
async def create_game_session(session_data: dict):
    # Business logic here
    pass

@trace_function("calculate_kolkhoz_scores")
async def calculate_kolkhoz_scores(session_id: str, game_events: list):
    # Complex calculation logic
    pass
```

### 8. Security Monitoring

**Security Event Logging**:
```python
# shared/monitoring/security.py
import hashlib
import ipaddress
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum

class SecurityEventType(Enum):
    AUTH_FAILURE = "auth_failure"
    BRUTE_FORCE = "brute_force_detected"
    SUSPICIOUS_IP = "suspicious_ip_access"
    DATA_BREACH_ATTEMPT = "data_breach_attempt"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    SQL_INJECTION = "sql_injection_attempt"
    XSS_ATTEMPT = "xss_attempt"
    RATE_LIMIT_EXCEEDED = "rate_limit_exceeded"
    UNAUTHORIZED_ACCESS = "unauthorized_access"
    SESSION_HIJACK = "session_hijack_attempt"

@dataclass
class SecurityEvent:
    event_type: SecurityEventType
    user_id: Optional[str]
    ip_address: str
    user_agent: str
    timestamp: datetime
    details: Dict
    severity: str  # low, medium, high, critical
    
class SecurityMonitor:
    def __init__(self):
        self.failed_attempts: Dict[str, List[datetime]] = {}
        self.suspicious_ips: set = set()
        self.blocked_ips: set = set()
    
    def log_security_event(self, event: SecurityEvent):
        """Log security event with structured data"""
        app_logger.warning(
            "Security event detected",
            event_type=event.event_type.value,
            user_id=event.user_id,
            ip_address=self._hash_ip(event.ip_address),
            user_agent=event.user_agent,
            severity=event.severity,
            details=event.details,
            category="security"
        )
        
        # Send to Sentry for critical events
        if event.severity == "critical":
            sentry_sdk.capture_message(
                f"Critical security event: {event.event_type.value}",
                level="error"
            )
    
    def check_brute_force(self, ip_address: str, user_id: Optional[str] = None) -> bool:
        """Check for brute force patterns"""
        key = f"{ip_address}:{user_id}" if user_id else ip_address
        now = datetime.utcnow()
        
        # Clean old attempts (older than 15 minutes)
        if key in self.failed_attempts:
            self.failed_attempts[key] = [
                attempt for attempt in self.failed_attempts[key]
                if now - attempt < timedelta(minutes=15)
            ]
        
        # Count recent attempts
        recent_attempts = len(self.failed_attempts.get(key, []))
        
        if recent_attempts >= 5:  # 5 attempts in 15 minutes
            self.log_security_event(SecurityEvent(
                event_type=SecurityEventType.BRUTE_FORCE,
                user_id=user_id,
                ip_address=ip_address,
                user_agent="",
                timestamp=now,
                details={"attempts_count": recent_attempts},
                severity="high"
            ))
            return True
        
        return False
    
    def record_failed_attempt(self, ip_address: str, user_id: Optional[str] = None):
        """Record authentication failure"""
        key = f"{ip_address}:{user_id}" if user_id else ip_address
        now = datetime.utcnow()
        
        if key not in self.failed_attempts:
            self.failed_attempts[key] = []
        
        self.failed_attempts[key].append(now)
        
        self.log_security_event(SecurityEvent(
            event_type=SecurityEventType.AUTH_FAILURE,
            user_id=user_id,
            ip_address=ip_address,
            user_agent="",
            timestamp=now,
            details={"total_attempts": len(self.failed_attempts[key])},
            severity="medium"
        ))
    
    def check_suspicious_patterns(self, request_data: Dict) -> bool:
        """Check for suspicious request patterns"""
        suspicious_patterns = [
            # SQL injection patterns
            r"(\bUNION\b|\bSELECT\b|\bINSERT\b|\bDELETE\b|\bDROP\b)",
            # XSS patterns
            r"(<script|javascript:|onload=|onerror=)",
            # Path traversal
            r"(\.\./|\.\.\\)",
            # Command injection
            r"(\b(rm|cat|ls|ps|wget|curl)\b)"
        ]
        
        # Check all string values in request
        for pattern in suspicious_patterns:
            for value in self._extract_string_values(request_data):
                if re.search(pattern, value, re.IGNORECASE):
                    return True
        
        return False
    
    def _hash_ip(self, ip_address: str) -> str:
        """Hash IP address for privacy"""
        return hashlib.sha256(ip_address.encode()).hexdigest()[:16]
    
    def _extract_string_values(self, data: Dict) -> List[str]:
        """Extract all string values from nested dict"""
        values = []
        
        def extract_recursive(obj):
            if isinstance(obj, str):
                values.append(obj)
            elif isinstance(obj, dict):
                for v in obj.values():
                    extract_recursive(v)
            elif isinstance(obj, list):
                for item in obj:
                    extract_recursive(item)
        
        extract_recursive(data)
        return values

# Security middleware
class SecurityMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, security_monitor: SecurityMonitor):
        super().__init__(app)
        self.security_monitor = security_monitor
    
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        client_ip = request.client.host
        user_agent = request.headers.get('user-agent', '')
        
        # Check if IP is blocked
        if client_ip in self.security_monitor.blocked_ips:
            return Response("Access denied", status_code=403)
        
        # Check for suspicious patterns in request
        try:
            if request.method in ["POST", "PUT", "PATCH"]:
                body = await request.body()
                if body:
                    request_data = json.loads(body.decode())
                    if self.security_monitor.check_suspicious_patterns(request_data):
                        self.security_monitor.log_security_event(SecurityEvent(
                            event_type=SecurityEventType.SQL_INJECTION,
                            user_id=None,
                            ip_address=client_ip,
                            user_agent=user_agent,
                            timestamp=datetime.utcnow(),
                            details={"endpoint": str(request.url)},
                            severity="high"
                        ))
                        return Response("Bad request", status_code=400)
        
        except Exception:
            pass  # Continue processing if body parsing fails
        
        response = await call_next(request)
        
        # Monitor response times for potential DoS
        duration = time.time() - start_time
        if duration > 10:  # Requests taking more than 10 seconds
            self.security_monitor.log_security_event(SecurityEvent(
                event_type=SecurityEventType.SUSPICIOUS_IP,
                user_id=None,
                ip_address=client_ip,
                user_agent=user_agent,
                timestamp=datetime.utcnow(),
                details={"slow_request_duration": duration},
                severity="medium"
            ))
        
        return response

# Global security monitor instance
security_monitor = SecurityMonitor()
```

### 9. Data Retention & Cost Optimization

**Retention Policies Configuration**:
```yaml
# monitoring/retention-policies.yml
retention_policies:
  logs:
    # Application logs
    application:
      hot_tier: "7d"      # Immediately searchable
      warm_tier: "30d"    # Compressed, slower search
      cold_tier: "90d"    # Archived, slow retrieval
      deletion: "1y"      # Permanent deletion
    
    # Error logs (keep longer)
    errors:
      hot_tier: "14d"
      warm_tier: "60d"
      cold_tier: "180d"
      deletion: "2y"
    
    # Security logs (regulatory compliance)
    security:
      hot_tier: "30d"
      warm_tier: "90d"
      cold_tier: "365d"
      deletion: "7y"
    
    # Access logs
    access:
      hot_tier: "3d"
      warm_tier: "14d"
      cold_tier: "30d"
      deletion: "90d"
  
  metrics:
    # High-resolution metrics (15s intervals)
    high_resolution:
      retention: "7d"
      downsampling:
        - resolution: "1m"
          retention: "30d"
        - resolution: "5m"
          retention: "90d"
        - resolution: "1h"
          retention: "1y"
    
    # Business metrics (important for analytics)
    business:
      retention: "2y"
      downsampling:
        - resolution: "1h"
          retention: "1y"
        - resolution: "1d"
          retention: "5y"
  
  traces:
    # Distributed traces
    traces:
      sampling_rate: 0.1  # 10% of traces
      retention: "14d"
    
    # Error traces (keep all)
    error_traces:
      sampling_rate: 1.0  # 100% of error traces
      retention: "30d"

cost_optimization:
  # Log compression
  compression:
    algorithm: "lz4"
    ratio: "~4:1"
  
  # Storage tiers
  storage_tiers:
    hot:
      type: "ssd"
      cost_per_gb_month: 0.15
    warm:
      type: "ssd_compressed"
      cost_per_gb_month: 0.08
    cold:
      type: "hdd_compressed"
      cost_per_gb_month: 0.03
  
  # Estimated monthly costs (per 100GB logs/day)
  estimated_costs:
    logs_monthly: "$450"
    metrics_monthly: "$200"
    traces_monthly: "$180"
    total_monthly: "$830"
```

**Automated Cleanup Scripts**:
```python
# scripts/cleanup_monitoring_data.py
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List
import logging

class MonitoringDataCleanup:
    def __init__(self, loki_client, prometheus_client, jaeger_client):
        self.loki = loki_client
        self.prometheus = prometheus_client
        self.jaeger = jaeger_client
        self.logger = logging.getLogger(__name__)
    
    async def cleanup_old_data(self):
        """Run all cleanup tasks"""
        tasks = [
            self.cleanup_logs(),
            self.cleanup_metrics(),
            self.cleanup_traces(),
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.error(f"Cleanup task {i} failed: {result}")
            else:
                self.logger.info(f"Cleanup task {i} completed: {result}")
    
    async def cleanup_logs(self) -> Dict[str, int]:
        """Clean up old log data based on retention policies"""
        cleanup_stats = {
            "application_logs_deleted": 0,
            "error_logs_deleted": 0,
            "security_logs_deleted": 0,
            "access_logs_deleted": 0
        }
        
        # Define cutoff dates
        cutoffs = {
            "application": datetime.utcnow() - timedelta(days=365),
            "errors": datetime.utcnow() - timedelta(days=730),
            "security": datetime.utcnow() - timedelta(days=2555),  # 7 years
            "access": datetime.utcnow() - timedelta(days=90)
        }
        
        for log_type, cutoff_date in cutoffs.items():
            try:
                deleted_count = await self._delete_logs_before_date(
                    log_type, cutoff_date
                )
                cleanup_stats[f"{log_type}_logs_deleted"] = deleted_count
                
                self.logger.info(
                    f"Deleted {deleted_count} {log_type} log entries older than {cutoff_date}"
                )
                
            except Exception as e:
                self.logger.error(f"Failed to cleanup {log_type} logs: {e}")
        
        return cleanup_stats
    
    async def cleanup_metrics(self) -> Dict[str, int]:
        """Clean up old metric data with downsampling"""
        cleanup_stats = {
            "high_res_metrics_deleted": 0,
            "downsampled_metrics_created": 0
        }
        
        # Delete high-resolution metrics older than 7 days
        cutoff_date = datetime.utcnow() - timedelta(days=7)
        
        try:
            # Downsample before deletion
            await self._downsample_metrics(cutoff_date)
            cleanup_stats["downsampled_metrics_created"] = 1
            
            # Delete original high-resolution data
            deleted_count = await self._delete_metrics_before_date(cutoff_date)
            cleanup_stats["high_res_metrics_deleted"] = deleted_count
            
        except Exception as e:
            self.logger.error(f"Failed to cleanup metrics: {e}")
        
        return cleanup_stats
    
    async def cleanup_traces(self) -> Dict[str, int]:
        """Clean up old trace data"""
        cleanup_stats = {
            "traces_deleted": 0,
            "error_traces_deleted": 0
        }
        
        # Delete regular traces older than 14 days
        regular_cutoff = datetime.utcnow() - timedelta(days=14)
        # Delete error traces older than 30 days
        error_cutoff = datetime.utcnow() - timedelta(days=30)
        
        try:
            regular_deleted = await self._delete_traces_before_date(
                regular_cutoff, include_errors=False
            )
            error_deleted = await self._delete_traces_before_date(
                error_cutoff, include_errors=True, errors_only=True
            )
            
            cleanup_stats["traces_deleted"] = regular_deleted
            cleanup_stats["error_traces_deleted"] = error_deleted
            
        except Exception as e:
            self.logger.error(f"Failed to cleanup traces: {e}")
        
        return cleanup_stats
    
    async def _delete_logs_before_date(self, log_type: str, cutoff_date: datetime) -> int:
        """Delete logs of specific type before cutoff date"""
        # Implementation depends on Loki API
        # This is a placeholder for the actual deletion logic
        query = f'{{category="{log_type}"}} | timestamp < {int(cutoff_date.timestamp())}'
        # deleted_count = await self.loki.delete_logs(query)
        deleted_count = 0  # Placeholder
        return deleted_count
    
    async def _downsample_metrics(self, cutoff_date: datetime):
        """Create downsampled versions of metrics"""
        # Implementation for metric downsampling
        pass
    
    async def _delete_metrics_before_date(self, cutoff_date: datetime) -> int:
        """Delete metrics before cutoff date"""
        # Implementation depends on Prometheus admin API
        deleted_count = 0  # Placeholder
        return deleted_count
    
    async def _delete_traces_before_date(self, cutoff_date: datetime, 
                                       include_errors: bool = True,
                                       errors_only: bool = False) -> int:
        """Delete traces before cutoff date"""
        # Implementation depends on Jaeger API
        deleted_count = 0  # Placeholder
        return deleted_count

# Cron job script
async def main():
    # Initialize clients
    loki_client = None  # Initialize Loki client
    prometheus_client = None  # Initialize Prometheus client
    jaeger_client = None  # Initialize Jaeger client
    
    cleanup = MonitoringDataCleanup(loki_client, prometheus_client, jaeger_client)
    
    try:
        stats = await cleanup.cleanup_old_data()
        print(f"Cleanup completed successfully: {stats}")
    except Exception as e:
        print(f"Cleanup failed: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
```

### 10. Health Checks & SLA Monitoring

**Service Health Checks**:
```python
# shared/monitoring/health.py
from datetime import datetime, timedelta
from typing import Dict, Any, List
from enum import Enum
import asyncio
import aiohttp
import psutil

class HealthStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"

class HealthCheck:
    def __init__(self, name: str, check_func, timeout: int = 30):
        self.name = name
        self.check_func = check_func
        self.timeout = timeout
        self.last_check = None
        self.last_status = None
        self.last_error = None
    
    async def run(self) -> Dict[str, Any]:
        """Run health check and return status"""
        start_time = datetime.utcnow()
        
        try:
            result = await asyncio.wait_for(
                self.check_func(),
                timeout=self.timeout
            )
            
            duration = (datetime.utcnow() - start_time).total_seconds()
            
            self.last_check = start_time
            self.last_status = HealthStatus.HEALTHY
            self.last_error = None
            
            return {
                "name": self.name,
                "status": HealthStatus.HEALTHY.value,
                "duration_ms": round(duration * 1000, 2),
                "details": result,
                "timestamp": start_time.isoformat()
            }
            
        except asyncio.TimeoutError:
            duration = (datetime.utcnow() - start_time).total_seconds()
            self.last_status = HealthStatus.UNHEALTHY
            self.last_error = "Timeout"
            
            return {
                "name": self.name,
                "status": HealthStatus.UNHEALTHY.value,
                "duration_ms": round(duration * 1000, 2),
                "error": "Health check timeout",
                "timestamp": start_time.isoformat()
            }
            
        except Exception as e:
            duration = (datetime.utcnow() - start_time).total_seconds()
            self.last_status = HealthStatus.UNHEALTHY
            self.last_error = str(e)
            
            return {
                "name": self.name,
                "status": HealthStatus.UNHEALTHY.value,
                "duration_ms": round(duration * 1000, 2),
                "error": str(e),
                "timestamp": start_time.isoformat()
            }

class HealthMonitor:
    def __init__(self):
        self.checks: List[HealthCheck] = []
        self.sla_targets = {
            "availability": 99.9,  # 99.9% uptime
            "response_time_p95": 500,  # 500ms P95 response time
            "error_rate": 1.0,  # Less than 1% error rate
        }
    
    def add_check(self, check: HealthCheck):
        """Add health check to monitor"""
        self.checks.append(check)
    
    async def check_database_health(self) -> Dict[str, Any]:
        """Check database connectivity and performance"""
        # Implementation for database health check
        return {
            "connection_pool": {"active": 5, "max": 20},
            "query_performance": {"avg_ms": 45},
            "replication_lag": {"ms": 12}
        }
    
    async def check_redis_health(self) -> Dict[str, Any]:
        """Check Redis connectivity and performance"""
        # Implementation for Redis health check
        return {
            "memory_usage": {"used_mb": 256, "max_mb": 1024},
            "connection_count": 45,
            "hit_rate": 0.89
        }
    
    async def check_rabbitmq_health(self) -> Dict[str, Any]:
        """Check RabbitMQ connectivity and queue status"""
        # Implementation for RabbitMQ health check
        return {
            "queue_lengths": {"game_events": 12, "notifications": 3},
            "connection_count": 8,
            "message_rate": {"in": 450, "out": 448}
        }
    
    async def check_external_services(self) -> Dict[str, Any]:
        """Check external service dependencies"""
        services = {
            "telegram_api": "https://api.telegram.org/bot/getMe",
            "sentry": "https://sentry.io/api/0/",
        }
        
        results = {}
        async with aiohttp.ClientSession() as session:
            for service, url in services.items():
                try:
                    async with session.get(url, timeout=10) as response:
                        results[service] = {
                            "status_code": response.status,
                            "response_time_ms": 150  # Placeholder
                        }
                except Exception as e:
                    results[service] = {"error": str(e)}
        
        return results
    
    async def check_system_resources(self) -> Dict[str, Any]:
        """Check system resource usage"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            "cpu_usage_percent": cpu_percent,
            "memory_usage_percent": memory.percent,
            "disk_usage_percent": (disk.used / disk.total) * 100,
            "load_average": psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else None
        }
    
    async def run_all_checks(self) -> Dict[str, Any]:
        """Run all health checks and return comprehensive status"""
        check_results = []
        
        # Run all registered checks
        for check in self.checks:
            result = await check.run()
            check_results.append(result)
        
        # Determine overall status
        overall_status = self._determine_overall_status(check_results)
        
        # Calculate SLA metrics
        sla_status = await self._calculate_sla_status()
        
        return {
            "overall_status": overall_status.value,
            "checks": check_results,
            "sla_status": sla_status,
            "timestamp": datetime.utcnow().isoformat(),
            "version": "1.0.0"
        }
    
    def _determine_overall_status(self, check_results: List[Dict]) -> HealthStatus:
        """Determine overall health status from individual checks"""
        unhealthy_count = sum(1 for check in check_results 
                             if check["status"] == HealthStatus.UNHEALTHY.value)
        degraded_count = sum(1 for check in check_results 
                            if check["status"] == HealthStatus.DEGRADED.value)
        
        if unhealthy_count > 0:
            return HealthStatus.UNHEALTHY
        elif degraded_count > 0:
            return HealthStatus.DEGRADED
        else:
            return HealthStatus.HEALTHY
    
    async def _calculate_sla_status(self) -> Dict[str, Any]:
        """Calculate SLA metrics"""
        # This would typically query metrics from Prometheus
        # Placeholder implementation
        return {
            "availability_percent": 99.95,
            "response_time_p95_ms": 450,
            "error_rate_percent": 0.5,
            "sla_targets": self.sla_targets,
            "sla_breaches": []
        }

# Setup health checks
health_monitor = HealthMonitor()

# Register health checks
health_monitor.add_check(HealthCheck("database", health_monitor.check_database_health))
health_monitor.add_check(HealthCheck("redis", health_monitor.check_redis_health))
health_monitor.add_check(HealthCheck("rabbitmq", health_monitor.check_rabbitmq_health))
health_monitor.add_check(HealthCheck("external_services", health_monitor.check_external_services))
health_monitor.add_check(HealthCheck("system_resources", health_monitor.check_system_resources))

# FastAPI health endpoint
@app.get("/health")
async def health_check():
    """Comprehensive health check endpoint"""
    return await health_monitor.run_all_checks()

@app.get("/health/live")
async def liveness_check():
    """Simple liveness check for Kubernetes"""
    return {"status": "alive", "timestamp": datetime.utcnow().isoformat()}

@app.get("/health/ready")
async def readiness_check():
    """Readiness check for Kubernetes"""
    # Check critical dependencies only
    critical_checks = ["database", "redis"]
    
    for check in health_monitor.checks:
        if check.name in critical_checks:
            result = await check.run()
            if result["status"] != HealthStatus.HEALTHY.value:
                return Response(
                    content=json.dumps({"status": "not_ready", "failed_check": check.name}),
                    status_code=503,
                    media_type="application/json"
                )
    
    return {"status": "ready", "timestamp": datetime.utcnow().isoformat()}
```

## Verification Checkpoint

### Monitoring & Logging System Verification:

‚úÖ **Architecture Selection**:
- Cloud-native observability —Å Loki + Prometheus + Grafana
- Hybrid elements (Sentry for error tracking)
- Distributed tracing —Å Tempo/Jaeger
- Comprehensive alerting —Å AlertManager

‚úÖ **Logging Strategy**:
- Structured logging —Å JSON format
- Context-aware logging (request_id, user_id, session_id)
- Log levels –∏ categorization
- Security-focused log filtering

‚úÖ **Metrics Collection**:
- Application metrics (HTTP, business events, errors)
- Infrastructure metrics (CPU, memory, disk, network)
- Custom game metrics (sessions, events, scores)
- Real-time dashboard integration

‚úÖ **Error Tracking**:
- Sentry integration –¥–ª—è comprehensive error monitoring
- Context-rich error reporting
- Performance issue detection
- User session replay capabilities

‚úÖ **Security Monitoring**:
- Authentication failure tracking
- Brute force detection
- Suspicious activity monitoring
- SQL injection –∏ XSS attempt detection

‚úÖ **Performance Monitoring**:
- Distributed tracing across microservices
- Custom span instrumentation
- Database query performance tracking
- WebSocket connection monitoring

‚úÖ **Alerting System**:
- Multi-tier alerting (info, warning, critical)
- Team-based alert routing
- Multiple notification channels (email, Slack, Telegram)
- SLA breach detection

‚úÖ **Cost Optimization**:
- Data retention policies
- Automated cleanup processes
- Storage tier management
- Compression strategies

‚úÖ **Operational Excellence**:
- Health check endpoints
- SLA monitoring
- Disaster recovery planning
- Comprehensive documentation

üé®üé®üé® **EXITING CREATIVE PHASE: MONITORING & LOGGING SYSTEM** üé®üé®üé®