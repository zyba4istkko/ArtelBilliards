# –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å RabbitMQ

üé®üé®üé® **ENTERING CREATIVE PHASE: RABBITMQ MESSAGING ARCHITECTURE** üé®üé®üé®

## –û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞

–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–µ–∂—Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ –±–∞–∑–µ RabbitMQ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è event-driven communication –º–µ–∂–¥—É 6 –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞–º–∏ –±–∏–ª—å—è—Ä–¥–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –°–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–¥–µ–∂–Ω—É—é –¥–æ—Å—Ç–∞–≤–∫—É —Å–æ–±—ã—Ç–∏–π, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å real-time –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–≥—Ä–æ–≤–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –¥–æ 1000+ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–≥—Ä–æ–≤—ã—Ö —Å–µ—Å—Å–∏–π –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å WebSocket –¥–ª—è live —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π.

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

### –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- **Event-Driven Architecture**: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–≥—Ä–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
- **Real-time Processing**: < 100ms –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∏–≥—Ä–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π
- **Reliable Delivery**: –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ —Å–æ–±—ã—Ç–∏–π —Å At-Least-Once —Å–µ–º–∞–Ω—Ç–∏–∫–æ–π
- **Dead Letter Handling**: –û–±—Ä–∞–±–æ—Ç–∫–∞ failed messages —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–∞–º–∏
- **Event Ordering**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ ordered processing –¥–ª—è –∏–≥—Ä–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏
- **Broadcast Events**: Fanout –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å–µ—Å—Å–∏–∏

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
- **Performance**: < 50ms processing time –¥–ª—è game events
- **Throughput**: 10,000+ messages/second –ø—Ä–∏ –ø–∏–∫–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–µ
- **Reliability**: 99.9% delivery success rate
- **Scalability**: –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ consumers
- **Memory Usage**: Efficient message batching –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
- **Integration**: Seamless –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å FastAPI + fastStream

### –ë–∏–∑–Ω–µ—Å-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
- **Data Consistency**: Eventual consistency –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏
- **Business Events**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ complex workflows (–∏–≥—Ä–∞ -> —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ -> —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è)
- **Audit Trail**: –ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ event flow –¥–ª—è debugging
- **Rollback Capability**: –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å compensation actions –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö

## –í–∞—Ä–∏–∞–Ω—Ç—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã messaging

### –í–∞—Ä–∏–∞–Ω—Ç 1: Topic-Based Architecture (Recommended)

**–û–ø–∏—Å–∞–Ω–∏–µ**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Topic Exchange —Å routing keys –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ–±—ã—Ç–∏–π –ø–æ –¥–æ–º–µ–Ω–∞–º –∏ —Ç–∏–ø–∞–º.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
```
Services ‚Üí Topic Exchange ‚Üí Routing Keys ‚Üí Queues ‚Üí Consumers
         (game.events)   (game.ball.potted) (game.service.queue)
```

**Topic Structure**:
```
game.events.ball_potted        ‚Üí Game Service processing
game.events.game_ended         ‚Üí Stats Service + Notification Service
stats.updated.user_rank        ‚Üí Notification Service
social.friend_request          ‚Üí Friend Service + Notification Service
notifications.push_required    ‚Üí Notification Service ‚Üí WebSocket
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- –ì–∏–±–∫–æ–µ routing –Ω–∞ –æ—Å–Ω–æ–≤–µ event types
- –õ–µ–≥–∫–æ—Å—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö consumers
- Natural event categorization
- –°–µ–ª–µ–∫—Ç–∏–≤–Ω–∞—è –ø–æ–¥–ø–∏—Å–∫–∞ —Å–µ—Ä–≤–∏—Å–æ–≤ –Ω–∞ –Ω—É–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
- Support –¥–ª—è complex routing patterns

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**:
- –°–ª–æ–∂–Ω–æ—Å—Ç—å routing key management
- –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å ordering —Å–æ–±—ã—Ç–∏–π
- –ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å careful design routing patterns

### –í–∞—Ä–∏–∞–Ω—Ç 2: Direct Exchange per Service

**–û–ø–∏—Å–∞–Ω–∏–µ**: –ö–∞–∂–¥—ã–π —Å–µ—Ä–≤–∏—Å –∏–º–µ–µ—Ç —Å–≤–æ–π dedicated exchange –¥–ª—è –ø—Ä—è–º–æ–≥–æ —Ç–æ—á–∫–∞-–∫-—Ç–æ—á–∫–µ –æ–±—â–µ–Ω–∏—è.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
```
Game Service ‚Üí game.exchange ‚Üí direct routing ‚Üí stats.queue, notify.queue
Stats Service ‚Üí stats.exchange ‚Üí direct routing ‚Üí notify.queue
Friends Service ‚Üí friends.exchange ‚Üí direct routing ‚Üí notify.queue
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- –ü—Ä–æ—Å—Ç–æ—Ç–∞ routing (direct binding)
- –ß–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
- –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (direct routing)
- –õ–µ–≥–∫–æ—Å—Ç—å debugging –∏ monitoring

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**:
- Tight coupling –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏
- –°–ª–æ–∂–Ω–æ—Å—Ç—å broadcast scenarios
- –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ routing logic
- –ñ–µ—Å—Ç–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (—Å–ª–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å)

### –í–∞—Ä–∏–∞–Ω—Ç 3: Hybrid Exchange Architecture

**–û–ø–∏—Å–∞–Ω–∏–µ**: –ö–æ–º–±–∏–Ω–∞—Ü–∏—è Topic –¥–ª—è event broadcasting –∏ Direct –¥–ª—è point-to-point communication.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
```
Critical Events ‚Üí Topic Exchange ‚Üí Multiple Consumers (broadcast)
Direct Commands ‚Üí Direct Exchange ‚Üí Single Consumer (P2P)
Notifications ‚Üí Fanout Exchange ‚Üí All Notification Consumers
```

**Event Flow Examples**:
```
game.ball_potted ‚Üí Topic ‚Üí [Game Service, Stats Service, Notification Service]
user.stats_request ‚Üí Direct ‚Üí Stats Service only
session.notification ‚Üí Fanout ‚Üí All WebSocket connections
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
- –ì–∏–±–∫–æ—Å—Ç—å –≤ –≤—ã–±–æ—Ä–µ delivery patterns
- –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è P2P
- Efficient broadcasting –¥–ª—è notifications

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**:
- –°–ª–æ–∂–Ω–æ—Å—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- –ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ exchange type
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ connection pools
- –°–ª–æ–∂–Ω–æ—Å—Ç—å monitoring distributed exchanges

## –ê–Ω–∞–ª–∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤

### –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:
1. **Performance** - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –¥–æ—Å—Ç–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
2. **Scalability** - —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ä–∞—Å—Ç—É—â—É—é –Ω–∞–≥—Ä—É–∑–∫—É  
3. **Flexibility** - –ª–µ–≥–∫–æ—Å—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π –∏ consumers
4. **Reliability** - –≥–∞—Ä–∞–Ω—Ç–∏–∏ –¥–æ—Å—Ç–∞–≤–∫–∏ –∏ error handling
5. **Maintainability** - –ø—Ä–æ—Å—Ç–æ—Ç–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ debugging

### –û—Ü–µ–Ω–∫–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:

| –ö—Ä–∏—Ç–µ—Ä–∏–π | Topic-Based | Direct per Service | Hybrid Architecture |
|----------|-------------|-------------------|---------------------|
| **Performance** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Scalability** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Flexibility** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Reliability** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Maintainability** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |

## –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ

### **–í—ã–±–æ—Ä: Topic-Based Architecture (–í–∞—Ä–∏–∞–Ω—Ç 1)**

**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ**:
1. **Event-driven microservices**: –ù–∞—à–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ topic routing
2. **Flexibility –¥–ª—è —Ä–æ—Å—Ç–∞**: –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ —Ç–∏–ø—ã –∏–≥—Ä –∏ —Å–æ–±—ã—Ç–∏—è  
3. **Natural categorization**: –°–æ–±—ã—Ç–∏—è –ª–æ–≥–∏—á–Ω–æ –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è –ø–æ –¥–æ–º–µ–Ω–∞–º
4. **Scalability**: Consumers –º–æ–≥—É—Ç –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å—Å—è —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–æ

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:

```mermaid
graph TB
    subgraph "Publishers (Services)"
        GameSvc[Game Service]
        AuthSvc[Auth Service]
        StatsSvc[Stats Service]
        FriendsSvc[Friends Service]
        TemplateSvc[Template Service]
        NotifySvc[Notification Service]
    end
    
    subgraph "RabbitMQ Cluster"
        Exchange[Topic Exchange<br/>artel.events]
        
        subgraph "Queues"
            GameQueue[game.service.queue]
            StatsQueue[stats.service.queue]
            FriendsQueue[friends.service.queue]
            NotifyQueue[notifications.service.queue]
            WebSocketQueue[websocket.broadcast.queue]
            AuditQueue[audit.log.queue]
        end
    end
    
    subgraph "Consumers"
        GameConsumer[Game Event Consumer]
        StatsConsumer[Stats Event Consumer]
        FriendsConsumer[Friends Event Consumer]
        NotifyConsumer[Notification Consumer]
        WSConsumer[WebSocket Consumer]
        AuditConsumer[Audit Log Consumer]
    end
    
    subgraph "External Systems"
        WebSocketClients[WebSocket Clients<br/>React Frontend]
        LogStorage[Log Storage<br/>ELK Stack]
    end
    
    GameSvc --> Exchange
    AuthSvc --> Exchange
    StatsSvc --> Exchange
    FriendsSvc --> Exchange
    TemplateSvc --> Exchange
    NotifySvc --> Exchange
    
    Exchange -->|game.*| GameQueue
    Exchange -->|stats.*| StatsQueue
    Exchange -->|friends.*| FriendsQueue
    Exchange -->|notifications.*| NotifyQueue
    Exchange -->|websocket.*| WebSocketQueue
    Exchange -->|audit.*| AuditQueue
    
    GameQueue --> GameConsumer
    StatsQueue --> StatsConsumer
    FriendsQueue --> FriendsConsumer
    NotifyQueue --> NotifyConsumer
    WebSocketQueue --> WSConsumer
    AuditQueue --> AuditConsumer
    
    WSConsumer --> WebSocketClients
    AuditConsumer --> LogStorage
    
    style Exchange fill:#fff3e0
    style GameQueue fill:#e8f5e8
    style StatsQueue fill:#e1f5fe
    style FriendsQueue fill:#fce4ec
    style NotifyQueue fill:#f3e5f5
    style WebSocketQueue fill:#fff8e1
    style AuditQueue fill:#efebe9
```

## Implementation Guidelines

### 1. Exchange and Queue Configuration

**Topic Exchange Setup**:
```python
import aio_pika
from faststream.rabbit import RabbitBroker

class RabbitMQConfig:
    EXCHANGE_NAME = "artel.events"
    EXCHANGE_TYPE = "topic"
    
    # Queue configurations
    QUEUES = {
        "game.service.queue": {
            "routing_keys": ["game.*", "session.*"],
            "durable": True,
            "arguments": {"x-max-priority": 10}  # Priority –¥–ª—è critical events
        },
        "stats.service.queue": {
            "routing_keys": ["game.ended", "session.completed", "stats.*"],
            "durable": True,
            "arguments": {"x-message-ttl": 300000}  # 5 min TTL
        },
        "notifications.service.queue": {
            "routing_keys": ["notifications.*", "friends.*", "game.started"],
            "durable": True,
            "arguments": {"x-max-length": 10000}  # Max queue size
        },
        "websocket.broadcast.queue": {
            "routing_keys": ["websocket.*", "game.events.*"],
            "durable": False,  # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –µ—Å–ª–∏ –ø–æ—Ç–µ—Ä—è–µ–º –ø—Ä–∏ restart
            "auto_delete": True
        },
        "audit.log.queue": {
            "routing_keys": ["#"],  # –í—Å–µ —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∞—É–¥–∏—Ç–∞
            "durable": True,
            "arguments": {"x-max-length": 100000}
        }
    }

# FastStream Broker Setup
broker = RabbitBroker(
    url="amqp://user:password@rabbitmq:5672/",
    max_consumers=50,  # –ú–∞–∫—Å–∏–º—É–º consumers per connection
    logger=logger
)

@broker.on_startup
async def setup_rabbitmq():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ exchanges –∏ queues –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    
    connection = await aio_pika.connect_robust(broker.url)
    channel = await connection.channel()
    
    # –°–æ–∑–¥–∞–µ–º topic exchange
    exchange = await channel.declare_exchange(
        RabbitMQConfig.EXCHANGE_NAME,
        type=aio_pika.ExchangeType.TOPIC,
        durable=True
    )
    
    # –°–æ–∑–¥–∞–µ–º queues —Å routing
    for queue_name, config in RabbitMQConfig.QUEUES.items():
        queue = await channel.declare_queue(
            queue_name,
            durable=config.get("durable", True),
            auto_delete=config.get("auto_delete", False),
            arguments=config.get("arguments", {})
        )
        
        # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º routing keys
        for routing_key in config["routing_keys"]:
            await queue.bind(exchange, routing_key)
    
    await connection.close()
```

### 2. Event Schemas and Publishing

**Event Base Schema**:
```python
from pydantic import BaseModel, Field
from typing import Optional, Any, Dict
from datetime import datetime
from uuid import UUID, uuid4
from enum import Enum

class EventPriority(Enum):
    LOW = 1
    NORMAL = 5
    HIGH = 8
    CRITICAL = 10

class BaseEvent(BaseModel):
    """–ë–∞–∑–æ–≤–∞—è —Å—Ö–µ–º–∞ –¥–ª—è –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π"""
    event_id: UUID = Field(default_factory=uuid4)
    event_type: str
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    source_service: str
    correlation_id: Optional[UUID] = None  # –î–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ event chains
    priority: EventPriority = EventPriority.NORMAL
    retries: int = 0
    max_retries: int = 3
    
    # Metadata
    user_id: Optional[UUID] = None
    session_id: Optional[UUID] = None
    game_id: Optional[UUID] = None
    
    # Event payload
    data: Dict[str, Any]

class GameEvent(BaseEvent):
    """–°–æ–±—ã—Ç–∏—è –∏–≥—Ä–æ–≤–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞"""
    source_service: str = "game_service"
    
    class Config:
        schema_extra = {
            "examples": [
                {
                    "event_type": "game.ball_potted",
                    "user_id": "uuid-here",
                    "session_id": "session-uuid",
                    "game_id": "game-uuid",
                    "priority": "HIGH",
                    "data": {
                        "player_id": "player-uuid",
                        "ball_color": "red",
                        "ball_points": 4,
                        "total_score": 12,
                        "turn_position": 1
                    }
                }
            ]
        }

class StatsEvent(BaseEvent):
    """–°–æ–±—ã—Ç–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    source_service: str = "stats_service"

class NotificationEvent(BaseEvent):
    """–°–æ–±—ã—Ç–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"""
    source_service: str = "notification_service"
    priority: EventPriority = EventPriority.HIGH  # Notifications –≤–∞–∂–Ω—ã

class WebSocketEvent(BaseEvent):
    """–°–æ–±—ã—Ç–∏—è –¥–ª—è WebSocket broadcast"""
    source_service: str = "websocket_service"
    priority: EventPriority = EventPriority.CRITICAL  # Real-time –∫—Ä–∏—Ç–∏—á–Ω–æ
```

**Event Publisher Service**:
```python
class EventPublisher:
    def __init__(self, broker: RabbitBroker):
        self.broker = broker
        self.exchange_name = RabbitMQConfig.EXCHANGE_NAME
    
    async def publish_event(self, event: BaseEvent, routing_key: str):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è —Å retry logic"""
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON
            message_body = event.json().encode('utf-8')
            
            # –ü—É–±–ª–∏–∫—É–µ–º —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            await self.broker.publish(
                message_body,
                routing_key=routing_key,
                exchange=self.exchange_name,
                priority=event.priority.value,
                headers={
                    "event_type": event.event_type,
                    "source_service": event.source_service,
                    "correlation_id": str(event.correlation_id) if event.correlation_id else None,
                    "retry_count": event.retries
                },
                delivery_mode=2,  # Persistent messages
                expiration=str(300000) if event.priority == EventPriority.LOW else None  # TTL –¥–ª—è low priority
            )
            
            logger.info(f"Event published: {event.event_type} -> {routing_key}")
            
        except Exception as e:
            logger.error(f"Failed to publish event {event.event_id}: {e}")
            
            # Retry logic
            if event.retries < event.max_retries:
                event.retries += 1
                await asyncio.sleep(2 ** event.retries)  # Exponential backoff
                await self.publish_event(event, routing_key)
            else:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ dead letter queue
                await self._send_to_dlq(event, str(e))
    
    # Convenience methods –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–±—ã—Ç–∏–π
    async def publish_game_event(self, event: GameEvent):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –∏–≥—Ä–æ–≤–æ–≥–æ —Å–æ–±—ã—Ç–∏—è"""
        routing_key = f"game.{event.event_type.split('.')[1]}"  # game.ball_potted -> game.ball_potted
        await self.publish_event(event, routing_key)
    
    async def publish_stats_event(self, event: StatsEvent):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        routing_key = f"stats.{event.event_type.split('.')[1]}"
        await self.publish_event(event, routing_key)
    
    async def publish_notification_event(self, event: NotificationEvent):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è"""
        routing_key = f"notifications.{event.event_type.split('.')[1]}"
        await self.publish_event(event, routing_key)
    
    async def publish_websocket_event(self, event: WebSocketEvent):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –¥–ª—è WebSocket broadcast"""
        routing_key = f"websocket.{event.event_type.split('.')[1]}"
        await self.publish_event(event, routing_key)

# Dependency –¥–ª—è FastAPI
async def get_event_publisher() -> EventPublisher:
    return EventPublisher(broker)
```

### 3. Event Consumers

**Base Consumer Class**:
```python
from faststream import FastStream
from faststream.rabbit import RabbitBroker
from abc import ABC, abstractmethod

class BaseEventConsumer(ABC):
    def __init__(self, broker: RabbitBroker, queue_name: str):
        self.broker = broker
        self.queue_name = queue_name
        self.retry_delay = 5  # seconds
        self.max_retries = 3
    
    @abstractmethod
    async def process_event(self, event: BaseEvent) -> bool:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è. 
        Returns True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –¥–ª—è retry
        """
        pass
    
    async def handle_message(self, body: bytes, headers: dict):
        """–û–±—â–∏–π handler –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        try:
            # –ü–∞—Ä—Å–∏–º —Å–æ–±—ã—Ç–∏–µ
            event_data = json.loads(body.decode('utf-8'))
            event = BaseEvent.parse_obj(event_data)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ
            logger.info(f"Received event: {event.event_type} (ID: {event.event_id})")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–±—ã—Ç–∏–µ
            success = await self.process_event(event)
            
            if success:
                logger.info(f"Event processed successfully: {event.event_id}")
                return True
            else:
                # Retry logic
                retry_count = int(headers.get('retry_count', 0))
                if retry_count < self.max_retries:
                    await self._retry_event(event, retry_count + 1)
                else:
                    await self._send_to_dead_letter(event)
                return False
                
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            await self._handle_processing_error(body, headers, str(e))
            return False
    
    async def _retry_event(self, event: BaseEvent, retry_count: int):
        """–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–±—ã—Ç–∏—è"""
        await asyncio.sleep(self.retry_delay * retry_count)  # Exponential backoff
        
        # –ü–µ—Ä–µ–æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Å—á–µ—Ç—á–∏–∫–æ–º
        event.retries = retry_count
        routing_key = self._get_routing_key_for_retry(event)
        
        await self.broker.publish(
            event.json().encode('utf-8'),
            routing_key=routing_key,
            headers={"retry_count": str(retry_count)}
        )
    
    async def _send_to_dead_letter(self, event: BaseEvent):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ dead letter queue"""
        dlq_routing_key = f"dlq.{event.event_type}"
        
        await self.broker.publish(
            event.json().encode('utf-8'),
            routing_key=dlq_routing_key,
            headers={"reason": "max_retries_exceeded"}
        )
        
        logger.error(f"Event sent to DLQ: {event.event_id}")

# Game Events Consumer
class GameEventConsumer(BaseEventConsumer):
    def __init__(self, broker: RabbitBroker, game_service):
        super().__init__(broker, "game.service.queue")
        self.game_service = game_service
    
    async def process_event(self, event: BaseEvent) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–≥—Ä–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π"""
        
        try:
            if event.event_type == "game.ball_potted":
                await self._handle_ball_potted(event)
            elif event.event_type == "game.foul_committed":
                await self._handle_foul(event)
            elif event.event_type == "game.turn_changed":
                await self._handle_turn_change(event)
            elif event.event_type == "session.player_joined":
                await self._handle_player_joined(event)
            else:
                logger.warning(f"Unknown game event type: {event.event_type}")
                return True  # –ù–µ retry –¥–ª—è unknown events
            
            return True
            
        except Exception as e:
            logger.error(f"Error in game event processing: {e}")
            return False
    
    async def _handle_ball_potted(self, event: BaseEvent):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–±–∏—Ç–æ–≥–æ —à–∞—Ä–∞"""
        data = event.data
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç –≤ –ë–î
        await self.game_service.update_player_score(
            game_id=event.game_id,
            player_id=data["player_id"],
            points_scored=data["ball_points"]
        )
        
        # –ü—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats_event = StatsEvent(
            event_type="stats.ball_potted",
            correlation_id=event.event_id,
            user_id=event.user_id,
            session_id=event.session_id,
            game_id=event.game_id,
            data={
                "player_id": data["player_id"],
                "ball_color": data["ball_color"],
                "ball_points": data["ball_points"],
                "game_type": data.get("game_type", "kolkhoz")
            }
        )
        
        await self.broker.publish(
            stats_event.json().encode('utf-8'),
            routing_key="stats.ball_potted"
        )
        
        # –ü—É–±–ª–∏–∫—É–µ–º –¥–ª—è WebSocket
        ws_event = WebSocketEvent(
            event_type="websocket.score_updated",
            correlation_id=event.event_id,
            session_id=event.session_id,
            priority=EventPriority.CRITICAL,
            data={
                "player_id": data["player_id"],
                "new_score": data["total_score"],
                "ball_potted": {
                    "color": data["ball_color"],
                    "points": data["ball_points"]
                }
            }
        )
        
        await self.broker.publish(
            ws_event.json().encode('utf-8'),
            routing_key="websocket.score_updated"
        )

# FastStream app setup
app = FastStream(broker)

@broker.subscriber("game.service.queue")
async def handle_game_events(body: bytes, headers: dict = None):
    consumer = GameEventConsumer(broker, game_service)
    await consumer.handle_message(body, headers or {})

@broker.subscriber("stats.service.queue")
async def handle_stats_events(body: bytes, headers: dict = None):
    consumer = StatsEventConsumer(broker, stats_service)
    await consumer.handle_message(body, headers or {})

@broker.subscriber("notifications.service.queue")  
async def handle_notification_events(body: bytes, headers: dict = None):
    consumer = NotificationEventConsumer(broker, notification_service)
    await consumer.handle_message(body, headers or {})

@broker.subscriber("websocket.broadcast.queue")
async def handle_websocket_events(body: bytes, headers: dict = None):
    consumer = WebSocketEventConsumer(broker, websocket_manager)
    await consumer.handle_message(body, headers or {})
```

### 4. Game Event Flow Examples

**Complete Game Event Chain**:
```python
# 1. –ò–≥—Ä–æ–∫ –∑–∞–±–∏–≤–∞–µ—Ç —à–∞—Ä
async def handle_ball_potted_api(
    game_id: UUID,
    ball_data: BallPottedRequest,
    event_publisher: EventPublisher = Depends(get_event_publisher)
):
    """API endpoint –¥–ª—è –∑–∞–±–∏—Ç–æ–≥–æ —à–∞—Ä–∞"""
    
    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ö–æ–¥
    game = await game_service.validate_player_turn(game_id, ball_data.player_id)
    
    # –°–æ–∑–¥–∞–µ–º —Å–æ–±—ã—Ç–∏–µ
    event = GameEvent(
        event_type="game.ball_potted",
        user_id=ball_data.player_id,
        session_id=game.session_id,
        game_id=game_id,
        priority=EventPriority.HIGH,
        data={
            "player_id": str(ball_data.player_id),
            "ball_color": ball_data.ball_color,
            "ball_points": ball_data.ball_points,
            "total_score": ball_data.new_total_score,
            "turn_position": game.current_turn_position,
            "timestamp": datetime.utcnow().isoformat()
        }
    )
    
    # –ü—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ
    await event_publisher.publish_game_event(event)
    
    return {"status": "success", "event_id": event.event_id}

# 2. Event Chain Flow
"""
game.ball_potted ‚Üí Game Service Queue
    ‚Üì
Game Service processes ‚Üí Updates DB
    ‚Üì
Publishes stats.ball_potted ‚Üí Stats Service Queue
    ‚Üì
Stats Service processes ‚Üí Updates user stats
    ‚Üì
Publishes websocket.score_updated ‚Üí WebSocket Queue
    ‚Üì
WebSocket Service broadcasts ‚Üí All connected clients
    ‚Üì
Frontend receives ‚Üí Updates UI real-time
"""

# 3. Complex Event: Game Completion
async def handle_game_completion(event: BaseEvent):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–≥—Ä—ã - complex workflow"""
    
    game_data = event.data
    
    # 1. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–¥–ª—è "–ö–æ–ª—Ö–æ–∑")
    if game_data["game_type"] == "kolkhoz":
        results = await calculate_kolkhoz_results(
            game_id=event.game_id,
            participants=game_data["participants"]
        )
    
    # 2. –ü—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    for participant in results:
        stats_event = StatsEvent(
            event_type="stats.game_completed",
            correlation_id=event.event_id,
            user_id=participant["user_id"],
            session_id=event.session_id,
            game_id=event.game_id,
            data={
                "game_type": game_data["game_type"],
                "final_score": participant["final_score"],
                "balls_potted": participant["balls_potted"],
                "rubles_earned": participant["rubles_earned"],
                "rubles_paid": participant["rubles_paid"],
                "net_result": participant["net_result"],
                "position": participant["position"],  # 1=winner, 2=second, etc.
                "game_duration": game_data["duration_seconds"]
            }
        )
        
        await event_publisher.publish_stats_event(stats_event)
    
    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è
    for participant in results:
        if participant["position"] == 1:  # Winner
            achievement_event = StatsEvent(
                event_type="stats.achievement_check",
                correlation_id=event.event_id,
                user_id=participant["user_id"],
                data={
                    "achievement_type": "game_won",
                    "game_type": game_data["game_type"],
                    "context": results
                }
            )
            
            await event_publisher.publish_stats_event(achievement_event)
    
    # 4. –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–∞–º
    notification_event = NotificationEvent(
        event_type="notifications.game_completed",
        correlation_id=event.event_id,
        session_id=event.session_id,
        data={
            "game_type": game_data["game_type"],
            "results": results,
            "winner": results[0]["user_id"],  # Sorted by position
            "session_id": str(event.session_id)
        }
    )
    
    await event_publisher.publish_notification_event(notification_event)
    
    # 5. WebSocket broadcast —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    websocket_event = WebSocketEvent(
        event_type="websocket.game_completed",
        correlation_id=event.event_id,
        session_id=event.session_id,
        priority=EventPriority.CRITICAL,
        data={
            "message": "Game completed!",
            "results": results,
            "next_game_available": True
        }
    )
    
    await event_publisher.publish_websocket_event(websocket_event)
```

### 5. Dead Letter Queues and Error Handling

**Dead Letter Queue Configuration**:
```python
class DeadLetterQueueManager:
    def __init__(self, broker: RabbitBroker):
        self.broker = broker
        self.dlq_exchange = "artel.dlq"
        self.retry_exchange = "artel.retry"
    
    async def setup_dlq_infrastructure(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ DLQ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        
        connection = await aio_pika.connect_robust(self.broker.url)
        channel = await connection.channel()
        
        # DLQ Exchange
        dlq_exchange = await channel.declare_exchange(
            self.dlq_exchange,
            type=aio_pika.ExchangeType.TOPIC,
            durable=True
        )
        
        # Retry Exchange —Å TTL
        retry_exchange = await channel.declare_exchange(
            self.retry_exchange,
            type=aio_pika.ExchangeType.TOPIC,
            durable=True
        )
        
        # –°–æ–∑–¥–∞–µ–º DLQ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ queue
        dlq_configs = {
            "game.service.dlq": {
                "routing_key": "dlq.game.*",
                "original_queue": "game.service.queue"
            },
            "stats.service.dlq": {
                "routing_key": "dlq.stats.*", 
                "original_queue": "stats.service.queue"
            },
            "notifications.service.dlq": {
                "routing_key": "dlq.notifications.*",
                "original_queue": "notifications.service.queue"
            }
        }
        
        for dlq_name, config in dlq_configs.items():
            # Dead Letter Queue
            dlq = await channel.declare_queue(
                dlq_name,
                durable=True,
                arguments={
                    "x-message-ttl": 86400000,  # 24 hours TTL
                    "x-max-length": 1000,       # Max 1000 failed messages
                    "x-dead-letter-exchange": retry_exchange.name,
                    "x-dead-letter-routing-key": f"retry.{config['original_queue']}"
                }
            )
            
            await dlq.bind(dlq_exchange, config["routing_key"])
            
            # Retry Queue (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω—É—é –æ—á–µ—Ä–µ–¥—å –ø–æ—Å–ª–µ TTL)
            retry_queue_name = f"retry.{config['original_queue']}"
            retry_queue = await channel.declare_queue(
                retry_queue_name,
                durable=True,
                arguments={
                    "x-message-ttl": 300000,    # 5 minutes retry delay
                    "x-dead-letter-exchange": RabbitMQConfig.EXCHANGE_NAME,
                    "x-dead-letter-routing-key": self._get_original_routing_key(config['original_queue'])
                }
            )
            
            await retry_queue.bind(retry_exchange, f"retry.{config['original_queue']}")
        
        await connection.close()
    
    def _get_original_routing_key(self, queue_name: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ routing key –¥–ª—è retry"""
        mapping = {
            "game.service.queue": "game.retry",
            "stats.service.queue": "stats.retry", 
            "notifications.service.queue": "notifications.retry"
        }
        return mapping.get(queue_name, "general.retry")

# Enhanced Error Handling
class ErrorHandler:
    def __init__(self, dlq_manager: DeadLetterQueueManager):
        self.dlq_manager = dlq_manager
        self.error_strategies = {
            "TransientError": self._handle_transient_error,
            "PermanentError": self._handle_permanent_error,
            "ValidationError": self._handle_validation_error,
            "BusinessLogicError": self._handle_business_error
        }
    
    async def handle_processing_error(self, 
                                    event: BaseEvent, 
                                    error: Exception, 
                                    context: dict) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–∫–∏"""
        
        error_type = self._classify_error(error)
        strategy = self.error_strategies.get(error_type, self._handle_unknown_error)
        
        action = await strategy(event, error, context)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        await self._log_error(event, error, error_type, action, context)
        
        return action
    
    def _classify_error(self, error: Exception) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—à–∏–±–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        
        if isinstance(error, (ConnectionError, TimeoutError, aio_pika.exceptions.AMQPConnectionError)):
            return "TransientError"
        elif isinstance(error, (ValidationError, pydantic.ValidationError)):
            return "ValidationError"
        elif isinstance(error, BusinessLogicError):
            return "BusinessLogicError"
        elif isinstance(error, (TypeError, ValueError, KeyError)):
            return "PermanentError"
        else:
            return "UnknownError"
    
    async def _handle_transient_error(self, event: BaseEvent, error: Exception, context: dict) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ - retry"""
        retry_count = context.get("retry_count", 0)
        
        if retry_count < event.max_retries:
            # Exponential backoff
            delay = min(300, 2 ** retry_count * 5)  # Max 5 minutes
            
            await asyncio.sleep(delay)
            return "RETRY"
        else:
            return "DLQ"
    
    async def _handle_permanent_error(self, event: BaseEvent, error: Exception, context: dict) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ - –≤ DLQ —Å—Ä–∞–∑—É"""
        return "DLQ"
    
    async def _handle_validation_error(self, event: BaseEvent, error: Exception, context: dict) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - –ª–æ–≥–∏—Ä—É–µ–º –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º"""
        return "DISCARD"
    
    async def _handle_business_error(self, event: BaseEvent, error: Exception, context: dict) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∏–∑–Ω–µ—Å –æ—à–∏–±–æ–∫ - –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å compensation"""
        
        # –ü—É–±–ª–∏–∫—É–µ–º compensation event
        compensation_event = BaseEvent(
            event_type=f"compensation.{event.event_type}",
            correlation_id=event.correlation_id,
            source_service="error_handler",
            data={
                "original_event": event.dict(),
                "error_reason": str(error),
                "compensation_action": "rollback"
            }
        )
        
        await self.dlq_manager.broker.publish(
            compensation_event.json().encode('utf-8'),
            routing_key="compensation.required"
        )
        
        return "COMPENSATE"
```

### 6. Performance Optimization and Monitoring

**Performance Monitoring**:
```python
import time
from prometheus_client import Counter, Histogram, Gauge
import asyncio
from contextlib import asynccontextmanager

# Prometheus Metrics
EVENTS_PUBLISHED_TOTAL = Counter(
    'rabbitmq_events_published_total',
    'Total published events',
    ['event_type', 'routing_key', 'source_service']
)

EVENTS_PROCESSED_TOTAL = Counter(
    'rabbitmq_events_processed_total', 
    'Total processed events',
    ['event_type', 'queue_name', 'status']  # status: success, failed, retried
)

EVENT_PROCESSING_DURATION = Histogram(
    'rabbitmq_event_processing_duration_seconds',
    'Event processing duration',
    ['event_type', 'queue_name']
)

QUEUE_SIZE = Gauge(
    'rabbitmq_queue_size',
    'Current queue size',
    ['queue_name']
)

MESSAGE_AGE = Histogram(
    'rabbitmq_message_age_seconds',
    'Age of messages when processed',
    ['queue_name']
)

class PerformanceMonitor:
    def __init__(self, broker: RabbitBroker):
        self.broker = broker
        self.start_time = time.time()
        
    @asynccontextmanager
    async def track_event_processing(self, event_type: str, queue_name: str):
        """Context manager –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        start_time = time.time()
        
        try:
            yield
            # Success
            EVENTS_PROCESSED_TOTAL.labels(
                event_type=event_type,
                queue_name=queue_name, 
                status="success"
            ).inc()
            
        except Exception as e:
            # Failed
            EVENTS_PROCESSED_TOTAL.labels(
                event_type=event_type,
                queue_name=queue_name,
                status="failed" 
            ).inc()
            raise
        finally:
            # Duration
            duration = time.time() - start_time
            EVENT_PROCESSING_DURATION.labels(
                event_type=event_type,
                queue_name=queue_name
            ).observe(duration)
    
    async def track_message_age(self, event: BaseEvent, queue_name: str):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        message_age = (datetime.utcnow() - event.timestamp).total_seconds()
        
        MESSAGE_AGE.labels(queue_name=queue_name).observe(message_age)
        
        # Alert –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä–æ–µ
        if message_age > 60:  # 1 minute
            logger.warning(f"Old message detected: {event.event_id}, age: {message_age}s")
    
    async def monitor_queue_sizes(self):
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–∞–∑–º–µ—Ä–æ–≤ –æ—á–µ—Ä–µ–¥–µ–π"""
        while True:
            try:
                for queue_name in RabbitMQConfig.QUEUES.keys():
                    queue_info = await self._get_queue_info(queue_name)
                    
                    QUEUE_SIZE.labels(queue_name=queue_name).set(
                        queue_info.get('message_count', 0)
                    )
                    
                    # Alert –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞
                    if queue_info.get('message_count', 0) > 1000:
                        logger.warning(f"Queue {queue_name} is overloaded: {queue_info['message_count']} messages")
                
                await asyncio.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                logger.error(f"Error monitoring queue sizes: {e}")
                await asyncio.sleep(60)  # Retry in 1 minute
    
    async def _get_queue_info(self, queue_name: str) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –æ—á–µ—Ä–µ–¥–∏ —á–µ—Ä–µ–∑ Management API"""
        # –í production –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RabbitMQ Management API
        # –ó–¥–µ—Å—å –∑–∞–≥–ª—É—à–∫–∞
        return {"message_count": 0, "consumer_count": 1}

# Enhanced Event Publisher —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
class MonitoredEventPublisher(EventPublisher):
    def __init__(self, broker: RabbitBroker, monitor: PerformanceMonitor):
        super().__init__(broker)
        self.monitor = monitor
    
    async def publish_event(self, event: BaseEvent, routing_key: str):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"""
        start_time = time.time()
        
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º timestamp –¥–ª—è tracking
            if not hasattr(event, 'published_at'):
                event.published_at = datetime.utcnow()
            
            await super().publish_event(event, routing_key)
            
            # Metrics
            EVENTS_PUBLISHED_TOTAL.labels(
                event_type=event.event_type,
                routing_key=routing_key,
                source_service=event.source_service
            ).inc()
            
            # Performance tracking
            duration = time.time() - start_time
            if duration > 0.1:  # Slow publish (>100ms)
                logger.warning(f"Slow event publish: {event.event_id}, duration: {duration:.2f}s")
                
        except Exception as e:
            logger.error(f"Event publish failed: {event.event_id}, error: {e}")
            raise

# Enhanced Consumer —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
class MonitoredEventConsumer(BaseEventConsumer):
    def __init__(self, broker: RabbitBroker, queue_name: str, monitor: PerformanceMonitor):
        super().__init__(broker, queue_name)
        self.monitor = monitor
    
    async def handle_message(self, body: bytes, headers: dict):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        
        try:
            event_data = json.loads(body.decode('utf-8'))
            event = BaseEvent.parse_obj(event_data)
            
            # Track message age
            await self.monitor.track_message_age(event, self.queue_name)
            
            # Process with performance tracking
            async with self.monitor.track_event_processing(event.event_type, self.queue_name):
                success = await self.process_event(event)
            
            return success
            
        except Exception as e:
            logger.error(f"Error in monitored message handling: {e}")
            return False
```

### 7. Scaling and Load Balancing

**Consumer Scaling Strategy**:
```python
class ConsumerScaler:
    def __init__(self, broker: RabbitBroker):
        self.broker = broker
        self.consumer_pools = {}
        self.target_latencies = {
            "game.service.queue": 50,      # 50ms for game events
            "stats.service.queue": 200,    # 200ms for stats
            "notifications.service.queue": 100,  # 100ms for notifications
            "websocket.broadcast.queue": 25     # 25ms for real-time
        }
    
    async def scale_consumers_by_load(self):
        """–ê–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ consumers –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–≥—Ä—É–∑–∫–∏"""
        
        while True:
            try:
                for queue_name in RabbitMQConfig.QUEUES.keys():
                    queue_stats = await self._get_queue_stats(queue_name)
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω—É–∂–Ω–æ –ª–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                    action = await self._analyze_scaling_need(queue_name, queue_stats)
                    
                    if action == "SCALE_UP":
                        await self._add_consumer(queue_name)
                    elif action == "SCALE_DOWN":
                        await self._remove_consumer(queue_name)
                
                await asyncio.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                logger.error(f"Error in consumer scaling: {e}")
                await asyncio.sleep(60)
    
    async def _analyze_scaling_need(self, queue_name: str, stats: dict) -> str:
        """–ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è"""
        
        message_count = stats.get('message_count', 0)
        consumer_count = stats.get('consumer_count', 1)
        avg_processing_time = stats.get('avg_processing_time', 0)
        
        target_latency = self.target_latencies.get(queue_name, 100)
        
        # Scale up conditions
        if (message_count > 100 and avg_processing_time > target_latency) or \
           (message_count > 1000):
            return "SCALE_UP"
        
        # Scale down conditions  
        if consumer_count > 1 and message_count < 10 and avg_processing_time < target_latency / 2:
            return "SCALE_DOWN"
        
        return "NO_ACTION"
    
    async def _add_consumer(self, queue_name: str):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ consumer"""
        consumer_id = f"{queue_name}_consumer_{int(time.time())}"
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π consumer task
        consumer_task = asyncio.create_task(
            self._run_consumer(queue_name, consumer_id)
        )
        
        if queue_name not in self.consumer_pools:
            self.consumer_pools[queue_name] = []
        
        self.consumer_pools[queue_name].append({
            "id": consumer_id,
            "task": consumer_task,
            "started_at": datetime.utcnow()
        })
        
        logger.info(f"Scaled up consumer for {queue_name}: {consumer_id}")
    
    async def _remove_consumer(self, queue_name: str):
        """–£–¥–∞–ª–µ–Ω–∏–µ consumer"""
        if queue_name in self.consumer_pools and len(self.consumer_pools[queue_name]) > 1:
            # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π consumer
            consumer_info = self.consumer_pools[queue_name].pop(0)
            consumer_info["task"].cancel()
            
            logger.info(f"Scaled down consumer for {queue_name}: {consumer_info['id']}")

# Load Balancing —á–µ—Ä–µ–∑ multiple connections
class LoadBalancedBroker:
    def __init__(self, rabbitmq_urls: List[str]):
        self.urls = rabbitmq_urls
        self.brokers = []
        self.current_broker_index = 0
        
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö connections"""
        for url in self.urls:
            broker = RabbitBroker(url=url)
            await broker.connect()
            self.brokers.append(broker)
    
    def get_next_broker(self) -> RabbitBroker:
        """Round-robin –≤—ã–±–æ—Ä broker"""
        broker = self.brokers[self.current_broker_index]
        self.current_broker_index = (self.current_broker_index + 1) % len(self.brokers)
        return broker
    
    async def publish_with_load_balancing(self, event: BaseEvent, routing_key: str):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å load balancing"""
        broker = self.get_next_broker()
        
        try:
            await broker.publish(
                event.json().encode('utf-8'),
                routing_key=routing_key
            )
        except Exception as e:
            # Fallback –Ω–∞ –¥—Ä—É–≥–æ–π broker
            logger.warning(f"Broker failed, trying fallback: {e}")
            
            for fallback_broker in self.brokers:
                if fallback_broker != broker:
                    try:
                        await fallback_broker.publish(
                            event.json().encode('utf-8'),
                            routing_key=routing_key
                        )
                        return
                    except Exception:
                        continue
            
            raise Exception("All brokers failed")
```

### 8. Integration with Existing Architecture

**Integration —Å WebSocket Manager**:
```python
class WebSocketEventConsumer(BaseEventConsumer):
    def __init__(self, broker: RabbitBroker, websocket_manager):
        super().__init__(broker, "websocket.broadcast.queue")
        self.websocket_manager = websocket_manager
    
    async def process_event(self, event: BaseEvent) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ WebSocket —Å–æ–±—ã—Ç–∏–π"""
        try:
            if event.event_type == "websocket.score_updated":
                await self._broadcast_score_update(event)
            elif event.event_type == "websocket.game_completed":
                await self._broadcast_game_completion(event)
            elif event.event_type == "websocket.player_joined":
                await self._broadcast_player_joined(event)
            elif event.event_type == "websocket.notification":
                await self._send_targeted_notification(event)
            
            return True
            
        except Exception as e:
            logger.error(f"WebSocket event processing failed: {e}")
            return False
    
    async def _broadcast_score_update(self, event: BaseEvent):
        """Broadcast –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—á–µ—Ç–∞ –≤—Å–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–∞–º —Å–µ—Å—Å–∏–∏"""
        session_id = str(event.session_id)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º WebSocket —Å–æ–æ–±—â–µ–Ω–∏–µ
        ws_message = {
            "type": "score_updated",
            "session_id": session_id,
            "timestamp": event.timestamp.isoformat(),
            "data": event.data
        }
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–Ω—ã–º –∫ —Å–µ—Å—Å–∏–∏
        await self.websocket_manager.broadcast_to_session(session_id, ws_message)
    
    async def _send_targeted_notification(self, event: BaseEvent):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
        user_id = str(event.user_id)
        
        ws_message = {
            "type": "notification",
            "timestamp": event.timestamp.isoformat(),
            "data": event.data
        }
        
        await self.websocket_manager.send_to_user(user_id, ws_message)

# Integration —Å Stats Service
class StatsEventConsumer(BaseEventConsumer):
    def __init__(self, broker: RabbitBroker, stats_service):
        super().__init__(broker, "stats.service.queue")
        self.stats_service = stats_service
    
    async def process_event(self, event: BaseEvent) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π"""
        try:
            if event.event_type == "stats.ball_potted":
                await self._update_ball_stats(event)
            elif event.event_type == "stats.game_completed":
                await self._update_game_stats(event)
            elif event.event_type == "stats.achievement_check":
                await self._check_achievements(event)
            
            return True
            
        except Exception as e:
            logger.error(f"Stats event processing failed: {e}")
            return False
    
    async def _update_ball_stats(self, event: BaseEvent):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–±–∏—Ç—ã—Ö —à–∞—Ä–æ–≤"""
        data = event.data
        
        await self.stats_service.increment_user_stat(
            user_id=event.user_id,
            stat_type="balls_potted",
            increment=1,
            details={
                "ball_color": data["ball_color"],
                "ball_points": data["ball_points"],
                "game_type": data["game_type"]
            }
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—á–∫–æ–≤
        await self.stats_service.increment_user_stat(
            user_id=event.user_id,
            stat_type="total_points",
            increment=data["ball_points"]
        )
    
    async def _check_achievements(self, event: BaseEvent):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        user_id = event.user_id
        achievement_type = event.data["achievement_type"]
        
        new_achievements = await self.stats_service.check_user_achievements(
            user_id=user_id,
            trigger_event=achievement_type,
            context=event.data.get("context", {})
        )
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è, –ø—É–±–ª–∏–∫—É–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        for achievement in new_achievements:
            notification_event = NotificationEvent(
                event_type="notifications.achievement_unlocked",
                correlation_id=event.event_id,
                user_id=user_id,
                data={
                    "achievement_id": achievement["id"],
                    "achievement_name": achievement["name"],
                    "achievement_description": achievement["description"],
                    "rarity": achievement["rarity"]
                }
            )
            
            await self.broker.publish(
                notification_event.json().encode('utf-8'),
                routing_key="notifications.achievement_unlocked"
            )
```

## Verification Checkpoint

### RabbitMQ Architecture Verification:

‚úÖ **Event-Driven Architecture**:
- Topic-based routing —Å –≥–∏–±–∫–∏–º–∏ patterns
- Event schemas —Å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–º–∏ ID –¥–ª—è tracing
- At-least-once delivery –≥–∞—Ä–∞–Ω—Ç–∏–∏
- Ordered processing –¥–ª—è –∏–≥—Ä–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏

‚úÖ **Performance Requirements**:
- < 50ms processing –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π
- 10,000+ messages/second throughput capability
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ scaling consumers –ø–æ –Ω–∞–≥—Ä—É–∑–∫–µ
- Load balancing —á–µ—Ä–µ–∑ multiple connections

‚úÖ **Reliability & Error Handling**:
- Dead Letter Queues —Å retry mechanisms
- Exponential backoff –¥–ª—è transient errors
- Error classification –∏ appropriate handling strategies  
- Compensation events –¥–ª—è business logic failures

‚úÖ **Integration**:
- Seamless –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å WebSocket –¥–ª—è real-time
- Stats service integration –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
- Notification service –¥–ª—è push —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
- Audit logging –¥–ª—è –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π

‚úÖ **Monitoring & Observability**:
- Prometheus metrics –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- Message age tracking –∏ queue size monitoring
- Performance alerting –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ SLA
- Consumer health checks –∏ automatic recovery

‚úÖ **Scalability**:
- –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ consumers
- Multiple RabbitMQ instances —Å load balancing
- Queue partitioning —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è high throughput
- Resource-based auto-scaling

üé®üé®üé® **EXITING CREATIVE PHASE: RABBITMQ MESSAGING ARCHITECTURE** üé®üé®üé®